
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../usage/">
      
      
        <link rel="next" href="../encode/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.45">
    
    
      
        <title>API Documentation: Core - FlowEvidence Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="pink">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#api-documentation-core" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="FlowEvidence Documentation" class="md-header__button md-logo" aria-label="FlowEvidence Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            FlowEvidence Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              API Documentation: Core
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="pink"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="amber"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/asantini29/flowevidence" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../installation/" class="md-tabs__link">
        
  
    
  
  Installation

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../usage/" class="md-tabs__link">
        
  
    
  
  Usage

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="./" class="md-tabs__link">
          
  
  API Documentation

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="FlowEvidence Documentation" class="md-nav__button md-logo" aria-label="FlowEvidence Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    FlowEvidence Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/asantini29/flowevidence" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Usage
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API Documentation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            API Documentation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" checked>
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Core
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Core
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    API Documentation: Core
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    API Documentation: Core
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#core-functions-and-wrappers-to-compute-the-evidence-given-different-inputs" class="md-nav__link">
    <span class="md-ellipsis">
      Core functions and wrappers to compute the evidence given different inputs.
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flowevidence.core" class="md-nav__link">
    <span class="md-ellipsis">
      core
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flowevidence.core.FlowContainer" class="md-nav__link">
    <span class="md-ellipsis">
      FlowContainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FlowContainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.FlowContainer.build_flow" class="md-nav__link">
    <span class="md-ellipsis">
      build_flow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.FlowContainer.load" class="md-nav__link">
    <span class="md-ellipsis">
      load
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.FlowContainer.load_data" class="md-nav__link">
    <span class="md-ellipsis">
      load_data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.FlowContainer.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flowevidence.core.EarlyStopping" class="md-nav__link">
    <span class="md-ellipsis">
      EarlyStopping
    </span>
  </a>
  
    <nav class="md-nav" aria-label="EarlyStopping">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.EarlyStopping.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flowevidence.core.EvidenceFlow" class="md-nav__link">
    <span class="md-ellipsis">
      EvidenceFlow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="EvidenceFlow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.EvidenceFlow.get_draws" class="md-nav__link">
    <span class="md-ellipsis">
      get_draws
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.EvidenceFlow.get_logZ" class="md-nav__link">
    <span class="md-ellipsis">
      get_logZ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flowevidence.core.ErynEvidenceFlow" class="md-nav__link">
    <span class="md-ellipsis">
      ErynEvidenceFlow
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Encode
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Encode
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../encode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API Documentation: Encode
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Utils
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            Utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API Documentation: Utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_4" >
        
          
          <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Transforms
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            Transforms
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transforms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API Documentation: Transforms
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#core-functions-and-wrappers-to-compute-the-evidence-given-different-inputs" class="md-nav__link">
    <span class="md-ellipsis">
      Core functions and wrappers to compute the evidence given different inputs.
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flowevidence.core" class="md-nav__link">
    <span class="md-ellipsis">
      core
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flowevidence.core.FlowContainer" class="md-nav__link">
    <span class="md-ellipsis">
      FlowContainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FlowContainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.FlowContainer.build_flow" class="md-nav__link">
    <span class="md-ellipsis">
      build_flow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.FlowContainer.load" class="md-nav__link">
    <span class="md-ellipsis">
      load
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.FlowContainer.load_data" class="md-nav__link">
    <span class="md-ellipsis">
      load_data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.FlowContainer.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flowevidence.core.EarlyStopping" class="md-nav__link">
    <span class="md-ellipsis">
      EarlyStopping
    </span>
  </a>
  
    <nav class="md-nav" aria-label="EarlyStopping">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.EarlyStopping.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flowevidence.core.EvidenceFlow" class="md-nav__link">
    <span class="md-ellipsis">
      EvidenceFlow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="EvidenceFlow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.EvidenceFlow.get_draws" class="md-nav__link">
    <span class="md-ellipsis">
      get_draws
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flowevidence.core.EvidenceFlow.get_logZ" class="md-nav__link">
    <span class="md-ellipsis">
      get_logZ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flowevidence.core.ErynEvidenceFlow" class="md-nav__link">
    <span class="md-ellipsis">
      ErynEvidenceFlow
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/asantini29/flowevidence/edit/main/docs/api/core.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"/></svg>
    </a>
  
  


<h1 id="api-documentation-core">API Documentation: Core</h1>
<h3 id="core-functions-and-wrappers-to-compute-the-evidence-given-different-inputs">Core functions and wrappers to compute the evidence given different inputs.</h3>


<div class="doc doc-object doc-module">



<a id="flowevidence.core"></a>
    <div class="doc doc-contents first">








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="flowevidence.core.FlowContainer" class="doc doc-heading">
            <code>FlowContainer</code>


</h2>


    <div class="doc doc-contents ">


        <p>A container for managing and training a flow-based model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code>Union[str, <span title="flowevidence.utils.torch.device">device</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device to run the model on. Default is 'cpu'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="flowevidence.utils.torch.dtype">dtype</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type for tensors. Default is torch.float64.</p>
              </div>
            </td>
            <td>
                  <code><span title="flowevidence.utils.torch.float64">float64</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbose</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to print verbose output during training. Default is False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="flowevidence.core.FlowContainer.build_flow" href="#flowevidence.core.FlowContainer.build_flow">build_flow</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Builds the flow model using the specified parameters.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="flowevidence.core.FlowContainer.load_data" href="#flowevidence.core.FlowContainer.load_data">load_data</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Loads the training and validation data loaders.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="flowevidence.core.FlowContainer.train" href="#flowevidence.core.FlowContainer.train">train</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Trains the flow model with the specified parameters.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="flowevidence.core.FlowContainer.load" href="#flowevidence.core.FlowContainer.load">load</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Loads a trained flow model from the specified path.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>flowevidence/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">FlowContainer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A container for managing and training a flow-based model.</span>

<span class="sd">    Args:</span>
<span class="sd">        device (Union[str, torch.device]): Device to run the model on. Default is &#39;cpu&#39;.</span>
<span class="sd">        dtype (torch.dtype): Data type for tensors. Default is torch.float64.</span>
<span class="sd">        verbose (bool): Whether to print verbose output during training. Default is False.</span>

<span class="sd">    Methods:</span>
<span class="sd">        build_flow(num_dims=None):</span>
<span class="sd">            Builds the flow model using the specified parameters.</span>
<span class="sd">        load_data(train_loader, val_loader=None):</span>
<span class="sd">            Loads the training and validation data loaders.</span>
<span class="sd">        train(start_epoch=0, epochs=1000, lr=1e-3, lambdaL2=None, path=&#39;./&#39;, filename=&#39;trainedflow.pth&#39;, target_distribution=None):</span>
<span class="sd">            Trains the flow model with the specified parameters.</span>
<span class="sd">        load(path=&#39;./&#39;, filename=&#39;trainedflow.pth&#39;):</span>
<span class="sd">            Loads a trained flow model from the specified path.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span>
                <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
                <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                <span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_default_dtype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">setup_logging</span><span class="p">(</span><span class="n">verbose</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">build_flow</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                   <span class="n">num_dims</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                   <span class="n">num_flow_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
                   <span class="n">transform_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;nvp&#39;</span><span class="p">,</span>
                   <span class="n">transform_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
                   <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Builds the flow model using the specified parameters.</span>
<span class="sd">        This method initializes the flow model by calling the `get_flow` function with the </span>
<span class="sd">        number of dimensions, number of flow steps, type of transformation, and device to be used for computation.</span>

<span class="sd">        Args:  </span>
<span class="sd">            num_dims (int): The number of dimensions for the flow model.</span>
<span class="sd">            num_flow_steps (int): The number of flow steps in the model. Default is 16.</span>
<span class="sd">            transform_type (str): The type of transformation to use. Default is &#39;nvp&#39;.</span>
<span class="sd">            transform_kwargs (dict): Additional keyword arguments for the transformation. Default is {}.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">flow</span> <span class="o">=</span> <span class="n">get_flow</span><span class="p">(</span><span class="n">num_dims</span><span class="p">,</span> 
                            <span class="n">num_flow_steps</span><span class="o">=</span><span class="n">num_flow_steps</span><span class="p">,</span> 
                            <span class="n">transform_type</span><span class="o">=</span><span class="n">transform_type</span><span class="p">,</span>
                            <span class="n">transform_kwargs</span><span class="o">=</span><span class="n">transform_kwargs</span><span class="p">,</span>
                            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataLoader</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads the training and validation data loaders.</span>

<span class="sd">        Args:</span>
<span class="sd">            train_loader (DataLoader): Training data loader.</span>
<span class="sd">            val_loader (DataLoader, optional): Validation data loader. Default is None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">train_loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="o">=</span> <span class="n">val_loader</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
              <span class="n">start_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> 
              <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> 
              <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> 
              <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
              <span class="n">lambdaL2</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
              <span class="n">early_stopping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
              <span class="n">stopping_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
              <span class="n">path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;./&#39;</span><span class="p">,</span> 
              <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;trainedflow.pth&#39;</span><span class="p">,</span> 
              <span class="n">target_distribution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
              <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the flow model.</span>

<span class="sd">        Args:</span>
<span class="sd">            start_epoch (int, optional): The starting epoch for training. Defaults to 0.</span>
<span class="sd">            epochs (int, optional): The number of epochs to train the model. Defaults to 1000.</span>
<span class="sd">            lr (float, optional): The learning rate for the optimizer. Defaults to 1e-3.</span>
<span class="sd">            weight_decay (float, optional): The weight decay for the optimizer. Defaults to 0.0.</span>
<span class="sd">            lambdaL2 (Optional[float], optional): The L2 regularization parameter. Defaults to None.</span>
<span class="sd">            early_stopping (Optional[bool], optional): Whether to use early stopping. Defaults to False.</span>
<span class="sd">            stopping_kwargs (Optional[dict], optional): Keyword arguments for early stopping. Defaults to {}.</span>
<span class="sd">            path (str, optional): The path to save the trained model and diagnostics. Defaults to &#39;./&#39;.</span>
<span class="sd">            filename (str, optional): The filename for the saved model. Defaults to &#39;trainedflow.pth&#39;.</span>
<span class="sd">            target_distribution (Optional[np.ndarray], optional): The target distribution for diagnostics. Defaults to None.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training flow for </span><span class="si">{}</span><span class="s2"> epochs&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epochs</span> <span class="o">-</span> <span class="n">start_epoch</span><span class="p">))</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span><span class="p">:</span>
            <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> 
                                                                <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                                                                <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                                                <span class="n">threshold</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="n">current_lr</span> <span class="o">=</span> <span class="n">lr</span>

        <span class="n">epochs_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">stopping_fn</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">early_stopping</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="n">early_stopping</span><span class="p">:</span>
            <span class="n">stopping_fn</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="o">**</span><span class="n">stopping_kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">early_stopping</span><span class="p">,</span> <span class="n">Callable</span><span class="p">):</span>
            <span class="n">stopping_fn</span> <span class="o">=</span> <span class="n">early_stopping</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Early stopping disabled&quot;</span><span class="p">)</span>

        <span class="n">trainedpath</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="n">filename</span>
        <span class="n">savepath</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="s2">&quot;diagnostic/&quot;</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">savepath</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training started&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving diagnostics to </span><span class="si">{</span><span class="n">savepath</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">epochs</span> <span class="o">&lt;</span> <span class="n">start_epoch</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Resuming training&quot;</span><span class="p">)</span>
            <span class="n">epochs</span> <span class="o">=</span> <span class="n">start_epoch</span> <span class="o">+</span> <span class="n">epochs</span>

        <span class="n">epoch_iterator</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">epochs</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">epoch_iterator</span><span class="p">:</span>
            <span class="n">train_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_one_epoch</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lambdaL2</span><span class="p">)</span>
            <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_one_epoch</span><span class="p">(</span><span class="n">lambdaL2</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="k">else</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>


            <span class="k">if</span> <span class="n">stopping_fn</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">stopping_fn</span><span class="p">(</span><span class="n">val_loss</span><span class="p">):</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Early stopping at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">converged</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>

            <span class="k">if</span> <span class="n">epoch</span>  <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_log_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">epochs_losses</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">target_distribution</span><span class="p">,</span> <span class="n">savepath</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">current_lr</span><span class="p">:</span>
                        <span class="n">current_lr</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New learning rate: </span><span class="si">{</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Saving model @ epoch </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">trainedpath</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">stopping_fn</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">converged</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Early stopping did not trigger&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">trainedpath</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Training finished&quot;</span><span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Saving diagnostics&quot;</span><span class="p">)</span>
        <span class="n">epochs_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
        <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save_diagnostics</span><span class="p">(</span><span class="n">epochs_losses</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">target_distribution</span><span class="p">,</span> <span class="n">savepath</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_train_one_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lambdaL2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the flow model for one epoch.</span>

<span class="sd">        Args:</span>
<span class="sd">            optimizer (torch.optim.Optimizer): The optimizer to use for training.</span>
<span class="sd">            lambdaL2 (Optional[float]): The L2 regularization parameter. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The average training loss for the epoch.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">Nbatches</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1">#number of batches that are not nan or inf</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

            <span class="c1"># Check if any samples are at the boundary</span>
            <span class="n">at_boundary</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.999</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">at_boundary</span><span class="p">):</span>
                <span class="c1"># Apply small jitter to boundary points to avoid numerical issues</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-4</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="c1">#breakpoint()</span>
            <span class="c1">#loss = loss_fn(self.flow, batch)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">forward_kld</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">l2_reg</span> <span class="o">=</span> <span class="n">l2_regularization</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="p">,</span> <span class="n">lambdaL2</span><span class="p">)</span> <span class="k">if</span> <span class="n">lambdaL2</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">l2_reg</span>
            <span class="k">if</span> <span class="o">~</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">loss</span><span class="p">)):</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">Nbatches</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Nbatches</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_validate_one_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lambdaL2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Validate the flow model for one epoch.</span>

<span class="sd">        Args:</span>
<span class="sd">            lambdaL2 (Optional[float]): The L2 regularization parameter. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The average validation loss for the epoch.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">Nbatches</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1">#number of batches that are not nan or inf</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span><span class="p">:</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">forward_kld</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="c1">#loss_fn(self.flow, batch)</span>
                <span class="n">l2_reg</span> <span class="o">=</span> <span class="n">l2_regularization</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="p">,</span> <span class="n">lambdaL2</span><span class="p">)</span> <span class="k">if</span> <span class="n">lambdaL2</span> <span class="k">else</span> <span class="mi">0</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">l2_reg</span>
                <span class="k">if</span> <span class="o">~</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">loss</span><span class="p">)):</span>
                    <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="n">Nbatches</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="c1"># else:</span>
                <span class="c1">#     breakpoint()</span>
        <span class="k">return</span> <span class="n">val_loss</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Nbatches</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_log_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">epochs_losses</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">target_distribution</span><span class="p">,</span> <span class="n">savepath</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Log the training and validation losses for the epoch.</span>

<span class="sd">        Args:</span>
<span class="sd">            epoch (int): The current epoch.</span>
<span class="sd">            train_loss (float): The training loss for the epoch.</span>
<span class="sd">            val_loss (float): The validation loss for the epoch.</span>
<span class="sd">            epochs_losses (list): List of epochs.</span>
<span class="sd">            train_losses (list): List of training losses.</span>
<span class="sd">            val_losses (list): List of validation losses.</span>
<span class="sd">            target_distribution (np.ndarray): The target distribution for diagnostics.</span>
<span class="sd">            savepath (str): The path to save the diagnostics.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">val_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s1">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">epochs_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
        <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_save_diagnostics</span><span class="p">(</span><span class="n">epochs_losses</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">target_distribution</span><span class="p">,</span> <span class="n">savepath</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">trainedpath</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the trained model.</span>

<span class="sd">        Args:</span>
<span class="sd">            epochs (int): The number of epochs trained.</span>
<span class="sd">            optimizer (torch.optim.Optimizer): The optimizer used for training.</span>
<span class="sd">            scheduler (torch.optim.lr_scheduler): The learning rate scheduler.</span>
<span class="sd">            trainedpath (str): The path to save the trained model.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">savedict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epochs</span><span class="p">,</span>
            <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;scheduler_state_dict&#39;</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="p">}</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">savedict</span><span class="p">,</span> <span class="n">trainedpath</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_save_diagnostics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs_losses</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">target_distribution</span><span class="p">,</span> <span class="n">savepath</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save diagnostics for the trained model.</span>

<span class="sd">        Args:</span>
<span class="sd">            epochs_losses (list): List of epochs.</span>
<span class="sd">            train_losses (list): List of training losses.</span>
<span class="sd">            val_losses (list): List of validation losses.</span>
<span class="sd">            target_distribution (np.ndarray): The target distribution for diagnostics.</span>
<span class="sd">            savepath (str): The path to save the diagnostics.</span>
<span class="sd">            ndim (int, optional): The number of dimensions to plot. Defaults to 10.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Nsamples_default</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e4</span><span class="p">)</span>
        <span class="n">Nsamples</span> <span class="o">=</span> <span class="n">target_distribution</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">target_distribution</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">Nsamples_default</span>
        <span class="n">Nsamples</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">Nsamples</span><span class="p">,</span> <span class="n">Nsamples_default</span><span class="p">)</span>

        <span class="n">samples_here</span><span class="p">,</span> <span class="n">log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">Nsamples</span><span class="p">)</span>
        <span class="n">samples_here</span> <span class="o">=</span> <span class="n">samples_here</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="n">lossplot</span><span class="p">(</span><span class="n">epochs_losses</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">plot_dir</span><span class="o">=</span><span class="n">savepath</span><span class="p">,</span> <span class="n">savename</span><span class="o">=</span><span class="s1">&#39;flow_loss&#39;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">cornerplot_training</span><span class="p">(</span><span class="n">samples_here</span><span class="p">[:,</span> <span class="p">:</span><span class="n">ndim</span><span class="p">],</span> <span class="n">target_distribution</span><span class="p">[:,</span> <span class="p">:</span><span class="n">ndim</span><span class="p">],</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epochs_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">plot_dir</span><span class="o">=</span><span class="n">savepath</span><span class="p">,</span> <span class="n">savename</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;flow_cornerplot&#39;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error plotting cornerplot: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Diagnostics saved&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;./&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;trainedflow.pth&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load a trained flow model from the specified path.</span>

<span class="sd">        Args:</span>
<span class="sd">            path (str, optional): The path to the saved model. Defaults to &#39;./&#39;.</span>
<span class="sd">            filename (str, optional): The filename of the saved model. Defaults to &#39;trainedflow.pth&#39;.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">loadpath</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="n">filename</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading flow from </span><span class="si">{</span><span class="n">loadpath</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">loadpath</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Flow loaded&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading flow: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="flowevidence.core.FlowContainer.build_flow" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">build_flow</span><span class="p">(</span><span class="n">num_dims</span><span class="p">,</span> <span class="n">num_flow_steps</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">transform_type</span><span class="o">=</span><span class="s1">&#39;nvp&#39;</span><span class="p">,</span> <span class="n">transform_kwargs</span><span class="o">=</span><span class="p">{})</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Builds the flow model using the specified parameters.
This method initializes the flow model by calling the <code>get_flow</code> function with the 
number of dimensions, number of flow steps, type of transformation, and device to be used for computation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>num_dims</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of dimensions for the flow model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_flow_steps</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of flow steps in the model. Default is 16.</p>
              </div>
            </td>
            <td>
                  <code>16</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>transform_type</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The type of transformation to use. Default is 'nvp'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;nvp&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>transform_kwargs</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional keyword arguments for the transformation. Default is {}.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>flowevidence/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">build_flow</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
               <span class="n">num_dims</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">num_flow_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
               <span class="n">transform_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;nvp&#39;</span><span class="p">,</span>
               <span class="n">transform_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
               <span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Builds the flow model using the specified parameters.</span>
<span class="sd">    This method initializes the flow model by calling the `get_flow` function with the </span>
<span class="sd">    number of dimensions, number of flow steps, type of transformation, and device to be used for computation.</span>

<span class="sd">    Args:  </span>
<span class="sd">        num_dims (int): The number of dimensions for the flow model.</span>
<span class="sd">        num_flow_steps (int): The number of flow steps in the model. Default is 16.</span>
<span class="sd">        transform_type (str): The type of transformation to use. Default is &#39;nvp&#39;.</span>
<span class="sd">        transform_kwargs (dict): Additional keyword arguments for the transformation. Default is {}.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">flow</span> <span class="o">=</span> <span class="n">get_flow</span><span class="p">(</span><span class="n">num_dims</span><span class="p">,</span> 
                        <span class="n">num_flow_steps</span><span class="o">=</span><span class="n">num_flow_steps</span><span class="p">,</span> 
                        <span class="n">transform_type</span><span class="o">=</span><span class="n">transform_type</span><span class="p">,</span>
                        <span class="n">transform_kwargs</span><span class="o">=</span><span class="n">transform_kwargs</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flowevidence.core.FlowContainer.load" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;trainedflow.pth&#39;</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Load a trained flow model from the specified path.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The path to the saved model. Defaults to './'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;./&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>filename</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The filename of the saved model. Defaults to 'trainedflow.pth'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;trainedflow.pth&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>flowevidence/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;./&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;trainedflow.pth&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load a trained flow model from the specified path.</span>

<span class="sd">    Args:</span>
<span class="sd">        path (str, optional): The path to the saved model. Defaults to &#39;./&#39;.</span>
<span class="sd">        filename (str, optional): The filename of the saved model. Defaults to &#39;trainedflow.pth&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">loadpath</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="n">filename</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading flow from </span><span class="si">{</span><span class="n">loadpath</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">loadpath</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Flow loaded&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading flow: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flowevidence.core.FlowContainer.load_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">load_data</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Loads the training and validation data loaders.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>train_loader</code>
            </td>
            <td>
                  <code><span title="flowevidence.utils.DataLoader">DataLoader</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Training data loader.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>val_loader</code>
            </td>
            <td>
                  <code><span title="flowevidence.utils.DataLoader">DataLoader</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Validation data loader. Default is None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>flowevidence/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataLoader</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads the training and validation data loaders.</span>

<span class="sd">    Args:</span>
<span class="sd">        train_loader (DataLoader): Training data loader.</span>
<span class="sd">        val_loader (DataLoader, optional): Validation data loader. Default is None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">train_loader</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="o">=</span> <span class="n">val_loader</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flowevidence.core.FlowContainer.train" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">train</span><span class="p">(</span><span class="n">start_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">lambdaL2</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">stopping_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">path</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;trainedflow.pth&#39;</span><span class="p">,</span> <span class="n">target_distribution</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Train the flow model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>start_epoch</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The starting epoch for training. Defaults to 0.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epochs</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of epochs to train the model. Defaults to 1000.</p>
              </div>
            </td>
            <td>
                  <code>1000</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lr</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The learning rate for the optimizer. Defaults to 1e-3.</p>
              </div>
            </td>
            <td>
                  <code>0.001</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>weight_decay</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The weight decay for the optimizer. Defaults to 0.0.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lambdaL2</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[float]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The L2 regularization parameter. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>early_stopping</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use early stopping. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stopping_kwargs</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[dict]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Keyword arguments for early stopping. Defaults to {}.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The path to save the trained model and diagnostics. Defaults to './'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;./&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>filename</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The filename for the saved model. Defaults to 'trainedflow.pth'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;trainedflow.pth&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>target_distribution</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="flowevidence.utils.np.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target distribution for diagnostics. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>flowevidence/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
          <span class="n">start_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> 
          <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> 
          <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> 
          <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
          <span class="n">lambdaL2</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
          <span class="n">early_stopping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
          <span class="n">stopping_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
          <span class="n">path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;./&#39;</span><span class="p">,</span> 
          <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;trainedflow.pth&#39;</span><span class="p">,</span> 
          <span class="n">target_distribution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
          <span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train the flow model.</span>

<span class="sd">    Args:</span>
<span class="sd">        start_epoch (int, optional): The starting epoch for training. Defaults to 0.</span>
<span class="sd">        epochs (int, optional): The number of epochs to train the model. Defaults to 1000.</span>
<span class="sd">        lr (float, optional): The learning rate for the optimizer. Defaults to 1e-3.</span>
<span class="sd">        weight_decay (float, optional): The weight decay for the optimizer. Defaults to 0.0.</span>
<span class="sd">        lambdaL2 (Optional[float], optional): The L2 regularization parameter. Defaults to None.</span>
<span class="sd">        early_stopping (Optional[bool], optional): Whether to use early stopping. Defaults to False.</span>
<span class="sd">        stopping_kwargs (Optional[dict], optional): Keyword arguments for early stopping. Defaults to {}.</span>
<span class="sd">        path (str, optional): The path to save the trained model and diagnostics. Defaults to &#39;./&#39;.</span>
<span class="sd">        filename (str, optional): The filename for the saved model. Defaults to &#39;trainedflow.pth&#39;.</span>
<span class="sd">        target_distribution (Optional[np.ndarray], optional): The target distribution for diagnostics. Defaults to None.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training flow for </span><span class="si">{}</span><span class="s2"> epochs&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epochs</span> <span class="o">-</span> <span class="n">start_epoch</span><span class="p">))</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span><span class="p">:</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> 
                                                            <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                                                            <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                                            <span class="n">threshold</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="n">current_lr</span> <span class="o">=</span> <span class="n">lr</span>

    <span class="n">epochs_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">stopping_fn</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">converged</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">early_stopping</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="n">early_stopping</span><span class="p">:</span>
        <span class="n">stopping_fn</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="o">**</span><span class="n">stopping_kwargs</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">early_stopping</span><span class="p">,</span> <span class="n">Callable</span><span class="p">):</span>
        <span class="n">stopping_fn</span> <span class="o">=</span> <span class="n">early_stopping</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Early stopping disabled&quot;</span><span class="p">)</span>

    <span class="n">trainedpath</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="n">filename</span>
    <span class="n">savepath</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="s2">&quot;diagnostic/&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">savepath</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training started&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving diagnostics to </span><span class="si">{</span><span class="n">savepath</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">epochs</span> <span class="o">&lt;</span> <span class="n">start_epoch</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Resuming training&quot;</span><span class="p">)</span>
        <span class="n">epochs</span> <span class="o">=</span> <span class="n">start_epoch</span> <span class="o">+</span> <span class="n">epochs</span>

    <span class="n">epoch_iterator</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">epochs</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">epoch_iterator</span><span class="p">:</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_one_epoch</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lambdaL2</span><span class="p">)</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_one_epoch</span><span class="p">(</span><span class="n">lambdaL2</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="k">else</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>


        <span class="k">if</span> <span class="n">stopping_fn</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">stopping_fn</span><span class="p">(</span><span class="n">val_loss</span><span class="p">):</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Early stopping at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">converged</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="n">epoch</span>  <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">epochs_losses</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">target_distribution</span><span class="p">,</span> <span class="n">savepath</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">current_lr</span><span class="p">:</span>
                    <span class="n">current_lr</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;New learning rate: </span><span class="si">{</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Saving model @ epoch </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">trainedpath</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">stopping_fn</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">converged</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Early stopping did not trigger&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">trainedpath</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Training finished&quot;</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Saving diagnostics&quot;</span><span class="p">)</span>
    <span class="n">epochs_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
    <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
    <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_save_diagnostics</span><span class="p">(</span><span class="n">epochs_losses</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">target_distribution</span><span class="p">,</span> <span class="n">savepath</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flowevidence.core.EarlyStopping" class="doc doc-heading">
            <code>EarlyStopping</code>


</h2>


    <div class="doc doc-contents ">


        <p>Early stopping class to stop training the flow model when the validation loss does not improve.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>patience</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of epochs to wait before stopping training. Default is 50.</p>
              </div>
            </td>
            <td>
                  <code>50</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>delta</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Minimum change in the monitored quantity to qualify as an improvement. Default is 1e-6.</p>
              </div>
            </td>
            <td>
                  <code>0.0001</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="flowevidence.core.EarlyStopping.__call__" href="#flowevidence.core.EarlyStopping.__call__">__call__</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Checks if the validation loss has improved.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>flowevidence/utils.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">EarlyStopping</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Early stopping class to stop training the flow model when the validation loss does not improve.</span>

<span class="sd">    Args:</span>
<span class="sd">        patience (int): Number of epochs to wait before stopping training. Default is 50.</span>
<span class="sd">        delta (float): Minimum change in the monitored quantity to qualify as an improvement. Default is 1e-6.</span>

<span class="sd">    Methods:</span>
<span class="sd">        __call__(val_loss):</span>
<span class="sd">            Checks if the validation loss has improved.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">delta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delta</span> <span class="o">=</span> <span class="n">delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks if the validation loss has improved.</span>

<span class="sd">        Args:</span>
<span class="sd">            val_loss (float): The validation loss to check.</span>

<span class="sd">        Returns:</span>
<span class="sd">            stop (bool): True if the validation loss has not improved for the specified number of epochs, False otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="flowevidence.core.EarlyStopping.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Checks if the validation loss has improved.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>val_loss</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The validation loss to check.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>stop</code></td>            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>True if the validation loss has not improved for the specified number of epochs, False otherwise.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>flowevidence/utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Checks if the validation loss has improved.</span>

<span class="sd">    Args:</span>
<span class="sd">        val_loss (float): The validation loss to check.</span>

<span class="sd">    Returns:</span>
<span class="sd">        stop (bool): True if the validation loss has not improved for the specified number of epochs, False otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stop</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flowevidence.core.EvidenceFlow" class="doc doc-heading">
            <code>EvidenceFlow</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="flowevidence.core.FlowContainer" href="#flowevidence.core.FlowContainer">FlowContainer</a></code></p>


        <p>A class for computing the log evidence (logZ) using a trained flow model and the posterior values associated with MCMC samples.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>posterior_samples</code>
            </td>
            <td>
                  <code><span title="flowevidence.utils.np.ndarray">ndarray</span> or dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The posterior samples to use for training the flow model. If a dictionary, the values are concatenated along the last axis.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logposterior_values</code>
            </td>
            <td>
                  <code><span title="flowevidence.utils.np.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The log posterior values associated with the posterior samples.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_flow_steps</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of flow steps in the model. Default is 16.</p>
              </div>
            </td>
            <td>
                  <code>16</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>transform_type</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The type of transformation to use. Default is 'nvp'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;nvp&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>transform_kwargs</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional keyword arguments for the transformation. Default is {}.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code>str or <span title="flowevidence.utils.torch.device">device</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device to run the model on. Default is 'cpu'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbose</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to print verbose output during training. Default is False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="flowevidence.utils.torch.dtype">dtype</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type for tensors. Default is torch.float64.</p>
              </div>
            </td>
            <td>
                  <code><span title="flowevidence.utils.torch.float64">float64</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>Nbatches</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of batches. Default is 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>split_ratio</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Ratio to split data into training and validation sets. Default is 0.8.</p>
              </div>
            </td>
            <td>
                  <code>0.8</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conversion_method</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Method for data conversion to the flow latent space ('normalize_minmax' or 'normalize_gaussian'). 
                     Default is 'normalize_minmax'.    </p>
              </div>
            </td>
            <td>
                  <code>&#39;minmax&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>autoencoder</code>
            </td>
            <td>
                  <code><span title="flowevidence.utils.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An autoencoder to encode the training and validation samples. Default is None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_autoencoder_kwargs</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Keyword arguments for training the autoencoder. Default is {}.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><span title="flowevidence.core.EvidenceFlow._setup_conversions">_setup_conversions</span></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Sets up the conversion methods to the latent space.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="flowevidence.core.EvidenceFlow._process_posterior_samples">_process_posterior_samples</span></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Processes the posterior samples and converts them to tensors.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="flowevidence.core.EvidenceFlow._process_tensors">_process_tensors</span></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Processes tensors, shuffles samples, splits data, and creates data loaders.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="flowevidence.core.EvidenceFlow.get_logZ" href="#flowevidence.core.EvidenceFlow.get_logZ">get_logZ</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Computes the log evidence (logZ) by building and training the flow model if necessary.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>flowevidence/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">EvidenceFlow</span><span class="p">(</span><span class="n">FlowContainer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class for computing the log evidence (logZ) using a trained flow model and the posterior values associated with MCMC samples.</span>

<span class="sd">    Args:</span>
<span class="sd">        posterior_samples (np.ndarray or dict): The posterior samples to use for training the flow model. If a dictionary, the values are concatenated along the last axis.</span>
<span class="sd">        logposterior_values (np.ndarray): The log posterior values associated with the posterior samples.</span>
<span class="sd">        num_flow_steps (int): Number of flow steps in the model. Default is 16.</span>
<span class="sd">        transform_type (str): The type of transformation to use. Default is &#39;nvp&#39;.</span>
<span class="sd">        transform_kwargs (dict): Additional keyword arguments for the transformation. Default is {}.</span>
<span class="sd">        device (str or torch.device): Device to run the model on. Default is &#39;cpu&#39;.</span>
<span class="sd">        verbose (bool): Whether to print verbose output during training. Default is False.</span>
<span class="sd">        dtype (torch.dtype): Data type for tensors. Default is torch.float64.</span>
<span class="sd">        Nbatches (int): Number of batches. Default is 1.</span>
<span class="sd">        split_ratio (float): Ratio to split data into training and validation sets. Default is 0.8.</span>
<span class="sd">        conversion_method (str): Method for data conversion to the flow latent space (&#39;normalize_minmax&#39; or &#39;normalize_gaussian&#39;). </span>
<span class="sd">                                 Default is &#39;normalize_minmax&#39;.    </span>
<span class="sd">        autoencoder (nn.Module): An autoencoder to encode the training and validation samples. Default is None.</span>
<span class="sd">        train_autoencoder_kwargs (dict): Keyword arguments for training the autoencoder. Default is {}.</span>

<span class="sd">    Methods:</span>
<span class="sd">        _setup_conversions(conversion_method):</span>
<span class="sd">            Sets up the conversion methods to the latent space.</span>
<span class="sd">        _process_posterior_samples(posterior_samples):</span>
<span class="sd">            Processes the posterior samples and converts them to tensors.</span>
<span class="sd">        _process_tensors():</span>
<span class="sd">            Processes tensors, shuffles samples, splits data, and creates data loaders.</span>
<span class="sd">        get_logZ(load_kwargs={}, train_kwargs={}):</span>
<span class="sd">            Computes the log evidence (logZ) by building and training the flow model if necessary.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">posterior_samples</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">logposterior_values</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">num_flow_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span> 
                 <span class="n">transform_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;nvp&#39;</span><span class="p">,</span>
                 <span class="n">transform_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
                 <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> 
                 <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
                 <span class="n">Nbatches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                 <span class="n">split_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                 <span class="n">conversion_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;minmax&#39;</span><span class="p">,</span>
                 <span class="n">autoencoder</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">train_autoencoder_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
                 <span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">verbose</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_flow_steps</span> <span class="o">=</span> <span class="n">num_flow_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform_type</span> <span class="o">=</span> <span class="n">transform_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform_kwargs</span> <span class="o">=</span> <span class="n">transform_kwargs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">split_ratio</span> <span class="o">=</span> <span class="n">split_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setup_conversions</span><span class="p">(</span><span class="n">conversion_method</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_posterior_samples</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">Nsamples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dims_full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Nbatches</span> <span class="o">=</span> <span class="n">Nbatches</span> <span class="k">if</span> <span class="n">Nbatches</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nsamples</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nsamples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nsamples</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nbatches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logposterior_values</span> <span class="o">=</span> <span class="n">logposterior_values</span>

        <span class="c1"># Autoencoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span> <span class="o">=</span> <span class="n">autoencoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_autoencoder_kwargs</span> <span class="o">=</span> <span class="n">train_autoencoder_kwargs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_process_tensors</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_setup_conversions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">conversion_method</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets up the conversion methods for transforming data to and from latent space.</span>

<span class="sd">        Args:</span>
<span class="sd">            conversion_method (str): The method to use for conversion. Must be one of &#39;normalize_minmax&#39; or &#39;normalize_gaussian&#39;.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If an invalid conversion method is provided.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">allowed_methods</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;minmax&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">normalize_minmax</span><span class="p">,</span> <span class="n">denormalize_minmax</span><span class="p">),</span>
        <span class="s1">&#39;gaussian&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">normalize_gaussian</span><span class="p">,</span> <span class="n">normalize_gaussian</span><span class="p">),</span>
        <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">normalize_sigmoid</span><span class="p">,</span> <span class="n">denormalize_sigmoid</span><span class="p">),</span>
        <span class="c1">#&#39;logit&#39;: (normalize_logit, denormalize_logit)</span>
    <span class="p">}</span>

        <span class="k">if</span> <span class="n">conversion_method</span> <span class="ow">in</span> <span class="n">allowed_methods</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_to_latent_space</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_latent_space</span> <span class="o">=</span> <span class="n">allowed_methods</span><span class="p">[</span><span class="n">conversion_method</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid conversion method: </span><span class="si">{</span><span class="n">conversion_method</span><span class="si">}</span><span class="s2">. Choose from </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">allowed_methods</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_process_posterior_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">posterior_samples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Processes posterior samples by concatenating them if they are in dictionary form </span>
<span class="sd">        and converting them to a PyTorch tensor.</span>

<span class="sd">        Args:</span>
<span class="sd">            posterior_samples (dict or array-like): The posterior samples to process. </span>
<span class="sd">                If a dictionary, the values are concatenated along the last axis.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The processed posterior samples as a PyTorch tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">posterior_samples</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">posterior_samples</span><span class="o">.</span><span class="n">keys</span><span class="p">()],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">posterior_samples</span>

    <span class="k">def</span> <span class="nf">_process_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Processes the posterior samples by converting them to latent space, shuffling, </span>
<span class="sd">        splitting into training and validation sets, and creating data loaders.</span>
<span class="sd">        This method performs the following steps:</span>
<span class="sd">        1. Converts posterior samples to latent space.</span>
<span class="sd">        2. Shuffles the latent samples.</span>
<span class="sd">        3. Splits the shuffled samples into training and validation sets based on the split ratio.</span>
<span class="sd">        4. Creates data loaders for the training and validation sets.</span>
<span class="sd">        5. Loads the data using the created data loaders.</span>
<span class="sd">        6. If an autoencoder is provided, it is used to encode the training and validation samples.        </span>

<span class="sd">        Attributes:</span>
<span class="sd">            self.q1: The first component of the latent space representation.</span>
<span class="sd">            self.q2: The second component of the latent space representation.</span>
<span class="sd">            self.latent_target: The latent space representation of the posterior samples as a NumPy array.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">latent_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_latent_space</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_target</span> <span class="o">=</span> <span class="n">latent_samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1">#breakpoint()</span>

        <span class="n">shuffled_samples</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">latent_samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_ratio</span><span class="p">:</span>
            <span class="n">train_samples</span><span class="p">,</span> <span class="n">val_samples</span> <span class="o">=</span> <span class="n">split</span><span class="p">(</span><span class="n">shuffled_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_ratio</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">train_samples</span><span class="p">,</span> <span class="n">val_samples</span> <span class="o">=</span> <span class="n">shuffled_samples</span><span class="p">,</span> <span class="kc">None</span>

        <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span> <span class="o">=</span> <span class="n">create_data_loaders</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">val_samples</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sanity_check_autoencoder</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_autoencoder_kwargs</span><span class="p">)</span>
            <span class="n">train_samples</span><span class="p">,</span> <span class="n">val_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_tensors</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">val_samples</span><span class="p">)</span>
            <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span> <span class="o">=</span> <span class="n">create_data_loaders</span><span class="p">(</span><span class="n">train_samples</span><span class="p">,</span> <span class="n">val_samples</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sanity_check_autoencoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                                  <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> 
                                  <span class="n">val_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
                                  <span class="n">training_kwargs</span><span class="p">:</span> <span class="nb">dict</span>
                                  <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks if the autoencoder is trained and trains it if necessary.</span>

<span class="sd">        Args:</span>
<span class="sd">            train_loader (DataLoader): The training samples to train the autoencoder on.</span>
<span class="sd">            val_loader (DataLoader): The validation samples to train the autoencoder on.</span>
<span class="sd">            training_kwargs (dict): Keyword arguments for training the autoencoder.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_autoencoder_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;filename&#39;</span><span class="p">,</span> <span class="s1">&#39;autoencoder.pth&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">training_kwargs</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">filename</span><span class="p">):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading autoencoder&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">training_kwargs</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">filename</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Autoencoder not found&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
            <span class="c1"># check if autoencoder is trained. If not, train it</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Autoencoder already trained&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training autoencoder&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="o">**</span><span class="n">training_kwargs</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Autoencoder trained&quot;</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">_encode_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                        <span class="n">train_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
                        <span class="n">val_tensor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                        <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encodes the training and validation samples using the autoencoder. If the autoencoder is not trained, it will be trained. If the autoencoder is not provided, the samples are returned as is.</span>

<span class="sd">        Args:</span>
<span class="sd">            train_loader (DataLoader): The training samples to train the autoencoder on.</span>
<span class="sd">            val_loader (DataLoader): The validation samples to train the autoencoder on.</span>
<span class="sd">            training_kwargs (dict): Keyword arguments for training the autoencoder.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">train_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">train_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">val_tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">val_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">val_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">latent_target</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">train_tensor</span><span class="p">,</span> <span class="n">val_tensor</span>


    <span class="k">def</span> <span class="nf">get_logZ</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">load_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
                 <span class="n">train_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
                 <span class="p">):</span> 
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the log evidence (logZ) by building and training the flow model if necessary.</span>

<span class="sd">        Args:</span>
<span class="sd">            load_kwargs (dict): Keyword arguments for loading the flow model.</span>
<span class="sd">            train_kwargs (dict): Keyword arguments for training the flow model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            logZ (float): The mean log evidence.</span>
<span class="sd">            dlogZ (float): The standard deviation of the log evidence.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sanity_check_flow</span><span class="p">(</span><span class="n">load_kwargs</span><span class="p">,</span> <span class="n">train_kwargs</span><span class="p">)</span>

        <span class="n">logProb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">latent_target</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">logZ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logposterior_values</span> <span class="o">-</span> <span class="n">logProb</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">logZ</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LogZ: </span><span class="si">{</span><span class="n">mean</span><span class="si">}</span><span class="s2"> +/- </span><span class="si">{</span><span class="n">std</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span>

    <span class="k">def</span> <span class="nf">get_draws</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                  <span class="n">load_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span> 
                  <span class="n">train_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span> 
                  <span class="n">num_draws</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span>
                  <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Draw samples from the trained flow model. If no model is loaded or trained, it will be trained.</span>

<span class="sd">        Args:</span>
<span class="sd">            load_kwargs (dict): Keyword arguments for loading the flow model. Refer to the documentation for the `load` method.</span>
<span class="sd">            train_kwargs (dict): Keyword arguments for training the flow model. Refer to the documentation for the `train` method.</span>
<span class="sd">            num_draws (int, optional): The number of samples to draw. Defaults to 10000.</span>

<span class="sd">        Returns:</span>
<span class="sd">            samples (np.ndarray): The drawn samples transformed in the original space.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sanity_check_flow</span><span class="p">(</span><span class="n">load_kwargs</span><span class="p">,</span> <span class="n">train_kwargs</span><span class="p">)</span>
        <span class="n">samples</span><span class="p">,</span> <span class="n">log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_draws</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span><span class="p">:</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

        <span class="n">converted</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_latent_space</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">converted</span>

    <span class="k">def</span> <span class="nf">_sanity_check_flow</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                           <span class="n">load_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span> 
                           <span class="n">train_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}</span>
                           <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks if the flow model is loaded or trained and loads or trains it if necessary.</span>

<span class="sd">        Args:</span>
<span class="sd">            load_kwargs (dict): Keyword arguments for loading the flow model. Refer to the documentation for the `load` method.</span>
<span class="sd">            train_kwargs (dict): Keyword arguments for training the flow model. Refer to the documentation for the `train` method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;flow&#39;</span><span class="p">):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Building flow&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">build_flow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_dims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_flow_steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_type</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform_kwargs</span><span class="p">)</span>

        <span class="n">load</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="o">**</span><span class="n">load_kwargs</span><span class="p">)</span>
        <span class="n">train_kwargs_here</span> <span class="o">=</span> <span class="n">train_kwargs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">load</span><span class="p">:</span>
            <span class="n">train_kwargs_here</span><span class="p">[</span><span class="s1">&#39;target_distribution&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_target</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">if</span> <span class="s1">&#39;path&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">train_kwargs_here</span> <span class="ow">and</span> <span class="s1">&#39;path&#39;</span> <span class="ow">in</span> <span class="n">load_kwargs</span><span class="p">:</span>
                <span class="n">train_kwargs_here</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">load_kwargs</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span>

            <span class="k">if</span> <span class="s1">&#39;filename&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">train_kwargs_here</span> <span class="ow">and</span> <span class="s1">&#39;filename&#39;</span> <span class="ow">in</span> <span class="n">load_kwargs</span><span class="p">:</span>
                <span class="n">train_kwargs_here</span><span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">load_kwargs</span><span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">]</span>

            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training flow&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="o">**</span><span class="n">train_kwargs_here</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="flowevidence.core.EvidenceFlow.get_draws" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_draws</span><span class="p">(</span><span class="n">load_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">train_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">num_draws</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Draw samples from the trained flow model. If no model is loaded or trained, it will be trained.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>load_kwargs</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Keyword arguments for loading the flow model. Refer to the documentation for the <code>load</code> method.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_kwargs</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Keyword arguments for training the flow model. Refer to the documentation for the <code>train</code> method.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_draws</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of samples to draw. Defaults to 10000.</p>
              </div>
            </td>
            <td>
                  <code>10000</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>samples</code></td>            <td>
                  <code><span title="flowevidence.utils.np.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The drawn samples transformed in the original space.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>flowevidence/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_draws</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
              <span class="n">load_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span> 
              <span class="n">train_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span> 
              <span class="n">num_draws</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span>
              <span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Draw samples from the trained flow model. If no model is loaded or trained, it will be trained.</span>

<span class="sd">    Args:</span>
<span class="sd">        load_kwargs (dict): Keyword arguments for loading the flow model. Refer to the documentation for the `load` method.</span>
<span class="sd">        train_kwargs (dict): Keyword arguments for training the flow model. Refer to the documentation for the `train` method.</span>
<span class="sd">        num_draws (int, optional): The number of samples to draw. Defaults to 10000.</span>

<span class="sd">    Returns:</span>
<span class="sd">        samples (np.ndarray): The drawn samples transformed in the original space.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_sanity_check_flow</span><span class="p">(</span><span class="n">load_kwargs</span><span class="p">,</span> <span class="n">train_kwargs</span><span class="p">)</span>
    <span class="n">samples</span><span class="p">,</span> <span class="n">log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">num_draws</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span><span class="p">:</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

    <span class="n">converted</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_from_latent_space</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">converted</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flowevidence.core.EvidenceFlow.get_logZ" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_logZ</span><span class="p">(</span><span class="n">load_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">train_kwargs</span><span class="o">=</span><span class="p">{})</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Computes the log evidence (logZ) by building and training the flow model if necessary.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>load_kwargs</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Keyword arguments for loading the flow model.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_kwargs</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Keyword arguments for training the flow model.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>logZ</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The mean log evidence.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>dlogZ</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The standard deviation of the log evidence.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>flowevidence/core.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_logZ</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
             <span class="n">load_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
             <span class="n">train_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
             <span class="p">):</span> 
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the log evidence (logZ) by building and training the flow model if necessary.</span>

<span class="sd">    Args:</span>
<span class="sd">        load_kwargs (dict): Keyword arguments for loading the flow model.</span>
<span class="sd">        train_kwargs (dict): Keyword arguments for training the flow model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        logZ (float): The mean log evidence.</span>
<span class="sd">        dlogZ (float): The standard deviation of the log evidence.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_sanity_check_flow</span><span class="p">(</span><span class="n">load_kwargs</span><span class="p">,</span> <span class="n">train_kwargs</span><span class="p">)</span>

    <span class="n">logProb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">latent_target</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">logZ</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logposterior_values</span> <span class="o">-</span> <span class="n">logProb</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logZ</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">logZ</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LogZ: </span><span class="si">{</span><span class="n">mean</span><span class="si">}</span><span class="s2"> +/- </span><span class="si">{</span><span class="n">std</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flowevidence.core.ErynEvidenceFlow" class="doc doc-heading">
            <code>ErynEvidenceFlow</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="flowevidence.core.EvidenceFlow" href="#flowevidence.core.EvidenceFlow">EvidenceFlow</a></code></p>


        <p>Wrapper class for using the <code>EvidenceFlow</code> class directly with a backend from the <code>Eryn</code> mcmc sampler. 
It stores the samples and logP values in a file for faster loading.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>backend</code>
            </td>
            <td>
                  <code>str or <span title="eryn.backends.HDFBackend">HDFBackend</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The backend to load the samples from.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>loader</code>
            </td>
            <td>
                  <code><span title="pysco.eryn.SamplesLoader">SamplesLoader</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A pysco.eryn.SamplesLoader object to load the samples from.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>samples_file</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The file to save the samples and logP values to. Default is './samples.h5'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;./samples.h5&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ess</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The effective sample size. Default is 1e4. It is used to compute the number of samples to discard and thin if they are <code>None</code>.</p>
              </div>
            </td>
            <td>
                  <code>int(10000.0)</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>discard</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of samples to discard. Default is None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>thin</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The thinning factor. Default is None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>leaves_to_ndim</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to reshape the leaves to ndim. Default is False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_flow_steps</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of flow steps in the model. Default is 16.</p>
              </div>
            </td>
            <td>
                  <code>16</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>transform_type</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The type of transformation to use. Default is 'nvp'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;nvp&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>transform_kwargs</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional keyword arguments for the transformation. Default is {}.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code>str or <span title="flowevidence.utils.torch.device">device</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device to run the model on. Default is 'cpu'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;cpu&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbose</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to print verbose output during training. Default is False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="flowevidence.utils.torch.dtype">dtype</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type for tensors. Default is torch.float64.</p>
              </div>
            </td>
            <td>
                  <code><span title="flowevidence.utils.torch.float64">float64</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>Nbatches</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of batches. Default is 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>split_ratio</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Ratio to split data into training and validation sets. Default is 0.8.</p>
              </div>
            </td>
            <td>
                  <code>0.8</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conversion_method</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Method for data conversion to the flow latent space ('normalize_minmax' or 'normalize_gaussian'). Default is 'normalize_minmax'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;normalize_minmax&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>autoencoder</code>
            </td>
            <td>
                  <code><span title="flowevidence.utils.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An autoencoder to encode the training and validation samples. Default is None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_autoencoder_kwargs</code>
            </td>
            <td>
                  <code>dict</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Keyword arguments for training the autoencoder. Default is {}.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>flowevidence/core.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ErynEvidenceFlow</span><span class="p">(</span><span class="n">EvidenceFlow</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper class for using the ``EvidenceFlow`` class directly with a backend from the ``Eryn`` mcmc sampler. </span>
<span class="sd">    It stores the samples and logP values in a file for faster loading.</span>

<span class="sd">    Args:</span>
<span class="sd">        backend (str or HDFBackend): The backend to load the samples from.</span>
<span class="sd">        loader (SamplesLoader): A pysco.eryn.SamplesLoader object to load the samples from.</span>
<span class="sd">        samples_file (str): The file to save the samples and logP values to. Default is &#39;./samples.h5&#39;.</span>
<span class="sd">        ess (int): The effective sample size. Default is 1e4. It is used to compute the number of samples to discard and thin if they are `None`.</span>
<span class="sd">        discard (int): The number of samples to discard. Default is None.</span>
<span class="sd">        thin (int): The thinning factor. Default is None.</span>
<span class="sd">        leaves_to_ndim (bool): Whether to reshape the leaves to ndim. Default is False.</span>
<span class="sd">        num_flow_steps (int): Number of flow steps in the model. Default is 16.</span>
<span class="sd">        transform_type (str): The type of transformation to use. Default is &#39;nvp&#39;.</span>
<span class="sd">        transform_kwargs (dict): Additional keyword arguments for the transformation. Default is {}.</span>
<span class="sd">        device (str or torch.device): Device to run the model on. Default is &#39;cpu&#39;.</span>
<span class="sd">        verbose (bool): Whether to print verbose output during training. Default is False.</span>
<span class="sd">        dtype (torch.dtype): Data type for tensors. Default is torch.float64.</span>
<span class="sd">        Nbatches (int): Number of batches. Default is 1.</span>
<span class="sd">        split_ratio (float): Ratio to split data into training and validation sets. Default is 0.8.</span>
<span class="sd">        conversion_method (str): Method for data conversion to the flow latent space (&#39;normalize_minmax&#39; or &#39;normalize_gaussian&#39;). Default is &#39;normalize_minmax&#39;.</span>
<span class="sd">        autoencoder (nn.Module): An autoencoder to encode the training and validation samples. Default is None.</span>
<span class="sd">        train_autoencoder_kwargs (dict): Keyword arguments for training the autoencoder. Default is {}.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">HDFBackend</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">loader</span><span class="p">:</span> <span class="n">SamplesLoader</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">samples_file</span><span class="p">:</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span> <span class="o">=</span> <span class="s1">&#39;./samples.h5&#39;</span><span class="p">,</span>
                <span class="n">ess</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e4</span><span class="p">),</span>
                <span class="n">discard</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">thin</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">leaves_to_ndim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                <span class="n">num_flow_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span> 
                <span class="n">transform_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;nvp&#39;</span><span class="p">,</span>
                <span class="n">transform_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span>
                <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> 
                <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
                <span class="n">Nbatches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                <span class="n">split_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
                <span class="n">conversion_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;normalize_minmax&#39;</span><span class="p">,</span>
                <span class="n">autoencoder</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">train_autoencoder_kwargs</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}):</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">eryn_here</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;Eryn is not installed. Please install Eryn to use this class, or </span><span class="se">\</span>
<span class="s2">                              use the EvidenceFlow class instead.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">samples_file</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">samples_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">results</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;results&#39;</span><span class="p">]</span>
                <span class="n">samples_group</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;samples&#39;</span><span class="p">]</span>
                <span class="n">samples</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">samples_group</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">samples</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples_group</span><span class="p">[</span><span class="n">key</span><span class="p">][:]</span>
                <span class="n">logP</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;logP&#39;</span><span class="p">][:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">backend</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either a backend or a loader must be provided.&quot;</span><span class="p">)</span>

            <span class="k">elif</span> <span class="n">loader</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">backend</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">pysco_here</span><span class="p">:</span>
                    <span class="n">loader</span> <span class="o">=</span> <span class="n">SamplesLoader</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>
                    <span class="n">samples</span><span class="p">,</span> <span class="n">logL</span><span class="p">,</span> <span class="n">logP</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ess</span><span class="o">=</span><span class="n">ess</span><span class="p">,</span> <span class="n">discard</span><span class="o">=</span><span class="n">discard</span><span class="p">,</span> <span class="n">thin</span><span class="o">=</span><span class="n">thin</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">leaves_to_ndim</span><span class="o">=</span><span class="n">leaves_to_ndim</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                        <span class="n">backend</span> <span class="o">=</span> <span class="n">HDFBackend</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>

                    <span class="n">samples</span><span class="p">,</span> <span class="n">logP</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_samples_posterior</span><span class="p">(</span><span class="n">backend</span><span class="p">,</span> <span class="n">ess</span><span class="p">,</span> <span class="n">leaves_to_ndim</span><span class="o">=</span><span class="n">leaves_to_ndim</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">samples</span><span class="p">,</span> <span class="n">logL</span><span class="p">,</span> <span class="n">logP</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ess</span><span class="o">=</span><span class="n">ess</span><span class="p">,</span> <span class="n">discard</span><span class="o">=</span><span class="n">discard</span><span class="p">,</span> <span class="n">thin</span><span class="o">=</span><span class="n">thin</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">leaves_to_ndim</span><span class="o">=</span><span class="n">leaves_to_ndim</span><span class="p">)</span>

            <span class="c1"># Save the samples and logP to a file</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">samples_file</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">samples_file</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">g</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="s1">&#39;results&#39;</span><span class="p">)</span>
                <span class="n">chain</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="s1">&#39;samples&#39;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">samples</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">chain</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">samples</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
                <span class="n">g</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;logP&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">logP</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">posterior_samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span> 
                         <span class="n">logposterior_values</span><span class="o">=</span><span class="n">logP</span><span class="p">,</span> 
                         <span class="n">num_flow_steps</span><span class="o">=</span><span class="n">num_flow_steps</span><span class="p">,</span> 
                         <span class="n">transform_type</span><span class="o">=</span><span class="n">transform_type</span><span class="p">,</span>
                         <span class="n">transform_kwargs</span><span class="o">=</span><span class="n">transform_kwargs</span><span class="p">,</span> 
                         <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> 
                         <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> 
                         <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> 
                         <span class="n">Nbatches</span><span class="o">=</span><span class="n">Nbatches</span><span class="p">,</span> 
                         <span class="n">split_ratio</span><span class="o">=</span><span class="n">split_ratio</span><span class="p">,</span> 
                         <span class="n">conversion_method</span><span class="o">=</span><span class="n">conversion_method</span><span class="p">,</span>
                         <span class="n">autoencoder</span><span class="o">=</span><span class="n">autoencoder</span><span class="p">,</span>
                         <span class="n">train_autoencoder_kwargs</span><span class="o">=</span><span class="n">train_autoencoder_kwargs</span>
                         <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_compute_discard_thin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                              <span class="n">samples</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> 
                              <span class="n">ess</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e4</span><span class="p">)</span>
                              <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the number of samples to discard and thin. Snippet adapted from from: `https://github.com/asantini29/pysco`</span>

<span class="sd">        Args:</span>
<span class="sd">            ess (int): Effective sample size. Default is 1e4.</span>

<span class="sd">        Returns:    </span>
<span class="sd">            discard (int): The number of samples to discard.</span>
<span class="sd">            thin (int): The thinning factor.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tau</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">samples</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">chain</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
            <span class="n">nsteps</span><span class="p">,</span> <span class="n">ntemps</span><span class="p">,</span> <span class="n">nw</span><span class="p">,</span> <span class="n">nleaves</span><span class="p">,</span> <span class="n">ndims</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">chain</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">nsteps</span><span class="p">,</span> <span class="n">ntemps</span><span class="p">,</span> <span class="n">nw</span><span class="p">,</span> <span class="n">nleaves</span> <span class="o">*</span> <span class="n">ndims</span><span class="p">)</span>
            <span class="n">tau</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_integrated_act</span><span class="p">(</span><span class="n">chain</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">taus_all</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">tau</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">tau_here</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">tau</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">tau_here</span><span class="p">):</span>
                <span class="n">taus_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tau_here</span><span class="p">)</span>

        <span class="n">thin</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">taus_all</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of steps: &quot;</span><span class="p">,</span> <span class="n">nsteps</span><span class="p">)</span>

        <span class="n">ess</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">ess</span><span class="p">)</span>
        <span class="n">N_keep</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">ess</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">thin</span> <span class="o">/</span> <span class="n">nw</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of samples to keep: &quot;</span><span class="p">,</span> <span class="n">N_keep</span><span class="p">)</span>
        <span class="n">discard</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">iteration</span> <span class="o">-</span> <span class="n">N_keep</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">discard</span><span class="p">,</span> <span class="n">thin</span>

    <span class="k">def</span> <span class="nf">_load_samples_posterior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                                <span class="n">backend</span><span class="p">:</span> <span class="n">HDFBackend</span><span class="p">,</span> 
                                <span class="n">ess</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
                                <span class="n">leaves_to_ndim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
                                <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load the samples from the backend. If the effective sample size is provided, the number of samples to discard and thin is computed.</span>
<span class="sd">        This is NOT compatible with reversible jump MCMC yet.</span>

<span class="sd">        Args:</span>
<span class="sd">            backend (HDFBackend): The backend to load the samples from.</span>
<span class="sd">            ess (int, optional): The effective sample size. Defaults to None.</span>
<span class="sd">            leaves_to_ndim (bool, optional): Whether to reshape the leaves to ndim. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            samples_out (dict): The samples.</span>
<span class="sd">            logP (np.ndarray): The log posterior values.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">samples</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_chain</span><span class="p">()</span>
        <span class="n">samples_out</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">ess</span><span class="p">:</span>
            <span class="n">discard</span><span class="p">,</span> <span class="n">thin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_discard_thin</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">ess</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">discard</span><span class="p">,</span> <span class="n">thin</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">samples</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">ns</span><span class="p">,</span> <span class="n">nt</span><span class="p">,</span> <span class="n">nw</span><span class="p">,</span> <span class="n">nl</span><span class="p">,</span> <span class="n">nd</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">if</span> <span class="n">leaves_to_ndim</span><span class="p">:</span>
                <span class="n">samples_out</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="n">discard</span><span class="p">::</span><span class="n">thin</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">nl</span><span class="o">*</span><span class="n">nd</span><span class="p">)</span> <span class="c1">#take the first temperature chain and flatten the rest</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">samples_out</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="n">discard</span><span class="p">::</span><span class="n">thin</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">nd</span><span class="p">)</span> <span class="c1">#take the first temperature chain and flatten the rest</span>

        <span class="n">logP</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_log_posterior</span><span class="p">(</span><span class="n">discard</span><span class="o">=</span><span class="n">discard</span><span class="p">,</span> <span class="n">thin</span><span class="o">=</span><span class="n">thin</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">samples_out</span><span class="p">,</span> <span class="n">logP</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>




  </div>

    </div>

</div>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 29, 2024</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 21, 2024</span>
  </span>

    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/asantini29" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:alessandro.santini@aei.mpg.de" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.top", "navigation.sections", "navigation.expand", "content.action.edit"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>