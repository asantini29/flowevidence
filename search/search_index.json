{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FlowEvidence","text":"<p><code>flowevidence</code> is a Python package that provides evidence estimations from a set of MCMC samples and the associated unnormalized (log-)posterior values. </p>"},{"location":"#getting-started","title":"Getting started:","text":"<p><code>flowevidence</code> estimates the posterior density by training a flow architecture directly on the samples. Then, for each of them, an evidence estimate can be computed as the ratio of the associated unnormalized posterior value and the flow pdf prediction.</p> <p>The source code is hosted [here](https://github.com/asantini29/flowevidence].</p>"},{"location":"#documentation-contents","title":"Documentation Contents","text":"<ul> <li>Installation</li> <li>Usage (TODO)</li> <li>API Reference</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#using-pip-not-available-yet","title":"Using pip (Not available yet)","text":"<pre><code>pip install flowevidence\n</code></pre>"},{"location":"installation/#from-source","title":"From source","text":"<pre><code>git clone https://github.com/asantini/flowevidence.git\ncd flowevidence\npython setup.py install\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>Here's a quick example of how to use FlowEvidence:</p> <pre><code>from flowevidence.core import CoreClass\nfrom flowevidence.utils import helper_function\n\n# Example usage\nobj = CoreClass()\nresult = helper_function(data)\nprint(result)\n</code></pre>"},{"location":"api/core/","title":"API Documentation: Core","text":""},{"location":"api/core/#core-functions-and-wrappers-to-compute-the-evidence-given-different-inputs","title":"Core functions and wrappers to compute the evidence given different inputs.","text":""},{"location":"api/core/#flowevidence.core.FlowContainer","title":"<code>FlowContainer</code>","text":"<p>A container for managing and training a flow-based model.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>Union[str, device]</code> <p>Device to run the model on. Default is 'cpu'.</p> <code>'cpu'</code> <code>dtype</code> <code>dtype</code> <p>Data type for tensors. Default is torch.float64.</p> <code>float64</code> <code>verbose</code> <code>bool</code> <p>Whether to print verbose output during training. Default is False.</p> <code>False</code> <p>Methods:</p> Name Description <code>build_flow</code> <p>Builds the flow model using the specified parameters.</p> <code>load_data</code> <p>Loads the training and validation data loaders.</p> <code>train</code> <p>Trains the flow model with the specified parameters.</p> <code>load</code> <p>Loads a trained flow model from the specified path.</p> Source code in <code>flowevidence/core.py</code> <pre><code>class FlowContainer:\n    \"\"\"\n    A container for managing and training a flow-based model.\n\n    Args:\n        device (Union[str, torch.device]): Device to run the model on. Default is 'cpu'.\n        dtype (torch.dtype): Data type for tensors. Default is torch.float64.\n        verbose (bool): Whether to print verbose output during training. Default is False.\n\n    Methods:\n        build_flow(num_dims=None):\n            Builds the flow model using the specified parameters.\n        load_data(train_loader, val_loader=None):\n            Loads the training and validation data loaders.\n        train(start_epoch=0, epochs=1000, lr=1e-3, lambdaL2=None, path='./', filename='trainedflow.pth', target_distribution=None):\n            Trains the flow model with the specified parameters.\n        load(path='./', filename='trainedflow.pth'):\n            Loads a trained flow model from the specified path.\n    \"\"\"\n\n    def __init__(self, \n                device: str | torch.device = 'cpu',\n                dtype: torch.dtype = torch.float64,\n                verbose: bool = False,\n                ):\n\n        self.device = torch.device(device) if isinstance(device, str) else device\n        self.dtype = dtype\n        torch.set_default_dtype(self.dtype)\n        setup_logging(verbose)\n        self.verbose = verbose\n\n        self.train_loader = None\n        self.val_loader = None\n\n    def build_flow(self, \n                   num_dims: int,\n                   num_flow_steps: int = 16,\n                   transform_type: str = 'nvp',\n                   transform_kwargs: dict = {},\n                   ):\n        \"\"\"\n        Builds the flow model using the specified parameters.\n        This method initializes the flow model by calling the `get_flow` function with the \n        number of dimensions, number of flow steps, type of transformation, and device to be used for computation.\n\n        Args:  \n            num_dims (int): The number of dimensions for the flow model.\n            num_flow_steps (int): The number of flow steps in the model. Default is 16.\n            transform_type (str): The type of transformation to use. Default is 'nvp'.\n            transform_kwargs (dict): Additional keyword arguments for the transformation. Default is {}.\n        \"\"\"\n\n        self.flow = get_flow(num_dims, \n                            num_flow_steps=num_flow_steps, \n                            transform_type=transform_type,\n                            transform_kwargs=transform_kwargs,\n                            device=self.device\n                            )\n\n    def load_data(self, train_loader: DataLoader, val_loader: Optional[DataLoader] = None):\n        \"\"\"\n        Loads the training and validation data loaders.\n\n        Args:\n            train_loader (DataLoader): Training data loader.\n            val_loader (DataLoader, optional): Validation data loader. Default is None.\n        \"\"\"\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n    def train(self, \n              start_epoch: int = 0, \n              epochs: int = 1000, \n              lr: float = 1e-3, \n              weight_decay: float = 0.0,\n              lambdaL2: Optional[float] = None,\n              early_stopping: bool | Callable = False,\n              stopping_kwargs: Optional[dict] = {},\n              path: str = './', \n              filename: str = 'trainedflow.pth', \n              target_distribution: Optional[np.ndarray] = None\n              ):\n        \"\"\"\n        Train the flow model.\n\n        Args:\n            start_epoch (int, optional): The starting epoch for training. Defaults to 0.\n            epochs (int, optional): The number of epochs to train the model. Defaults to 1000.\n            lr (float, optional): The learning rate for the optimizer. Defaults to 1e-3.\n            weight_decay (float, optional): The weight decay for the optimizer. Defaults to 0.0.\n            lambdaL2 (Optional[float], optional): The L2 regularization parameter. Defaults to None.\n            early_stopping (Optional[bool], optional): Whether to use early stopping. Defaults to False.\n            stopping_kwargs (Optional[dict], optional): Keyword arguments for early stopping. Defaults to {}.\n            path (str, optional): The path to save the trained model and diagnostics. Defaults to './'.\n            filename (str, optional): The filename for the saved model. Defaults to 'trainedflow.pth'.\n            target_distribution (Optional[np.ndarray], optional): The target distribution for diagnostics. Defaults to None.\n        \"\"\"\n\n        logging.info(\"Training flow for {} epochs\".format(epochs - start_epoch))\n\n        optimizer = torch.optim.Adam(self.flow.parameters(), lr=lr, weight_decay=weight_decay)\n        if self.val_loader:\n            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                                factor=0.5,\n                                                                patience=100,\n                                                                threshold=1e-4)\n\n        else:\n            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n\n        current_lr = lr\n\n        epochs_losses = []\n        train_losses = []\n        val_losses = []\n\n        stopping_fn = None\n        converged = False\n        if isinstance(early_stopping, bool) and early_stopping:\n            stopping_fn = EarlyStopping(**stopping_kwargs)\n        elif isinstance(early_stopping, Callable):\n            stopping_fn = early_stopping\n\n        else:\n            logging.info(\"Early stopping disabled\")\n\n        trainedpath = path + filename\n        savepath = path + \"diagnostic/\"\n        os.makedirs(savepath, exist_ok=True)\n\n        logging.info(\"Training started\")\n        logging.info(f\"Saving diagnostics to {savepath}\")\n\n        if epochs &lt; start_epoch:\n            logging.info(\"Resuming training\")\n            epochs = start_epoch + epochs\n\n        epoch_iterator = tqdm(range(start_epoch, epochs), desc=\"Training\", disable=not self.verbose)\n\n        for epoch in epoch_iterator:\n            train_loss = self._train_one_epoch(optimizer, lambdaL2)\n            val_loss = self._validate_one_epoch(lambdaL2) if self.val_loader else None\n            scheduler.step(val_loss) if self.val_loader else scheduler.step()\n\n\n            if stopping_fn:\n                if stopping_fn(val_loss):\n                    logging.info(f\"Early stopping at epoch {epoch}\")\n                    converged = True\n                    break\n\n            if epoch  &gt; 0 and epoch % 100 == 0:\n                if self.verbose:\n                    self._log_epoch(epoch, train_loss, val_loss, epochs_losses, train_losses, val_losses, target_distribution, savepath)\n                    if scheduler.get_last_lr()[0] != current_lr:\n                        current_lr = scheduler.get_last_lr()[0]\n                        logging.info(f\"New learning rate: {scheduler.get_last_lr()[0]}\")\n                    logging.info(\"Saving model @ epoch {}\".format(epoch))\n\n                self._save_model(epoch, optimizer, scheduler, trainedpath)\n\n        if stopping_fn and not converged:\n            logging.warning(\"Early stopping did not trigger\")\n\n        self._save_model(epochs, optimizer, scheduler, trainedpath)\n        logging.debug(\"Training finished\")\n\n        logging.debug(\"Saving diagnostics\")\n        epochs_losses.append(epoch)\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        self._save_diagnostics(epochs_losses, train_losses, val_losses, target_distribution, savepath)\n\n    def _train_one_epoch(self, optimizer, lambdaL2):\n        \"\"\"\n        Train the flow model for one epoch.\n\n        Args:\n            optimizer (torch.optim.Optimizer): The optimizer to use for training.\n            lambdaL2 (Optional[float]): The L2 regularization parameter. Defaults to None.\n\n        Returns:\n            float: The average training loss for the epoch.\n        \"\"\"\n\n        self.flow.train()\n        train_loss = 0\n        Nbatches = 0 #number of batches that are not nan or inf\n        for batch in self.train_loader:\n            batch = batch[0].to(self.device, non_blocking=self.device.type == 'cuda')\n\n            # Check if any samples are at the boundary\n            at_boundary = torch.any(torch.abs(batch) &gt; 0.999, dim=1)\n            if torch.any(at_boundary):\n                # Apply small jitter to boundary points to avoid numerical issues\n                batch = batch + torch.randn_like(batch) * 1e-4\n\n            optimizer.zero_grad()\n            #breakpoint()\n            #loss = loss_fn(self.flow, batch)\n            loss = self.flow.forward_kld(batch)\n            l2_reg = l2_regularization(self.flow, lambdaL2) if lambdaL2 else 0\n            loss = loss + l2_reg\n            if ~(torch.isnan(loss) | torch.isinf(loss)):\n                loss.backward()\n                optimizer.step()\n                train_loss += loss.item()\n                Nbatches += 1\n        return train_loss / max(1, Nbatches)\n\n    def _validate_one_epoch(self, lambdaL2):\n        \"\"\"\n        Validate the flow model for one epoch.\n\n        Args:\n            lambdaL2 (Optional[float]): The L2 regularization parameter. Defaults to None.\n\n        Returns:\n            float: The average validation loss for the epoch.\n        \"\"\"\n\n        self.flow.eval()\n        val_loss = 0\n        Nbatches = 0 #number of batches that are not nan or inf\n        with torch.no_grad():\n            for batch in self.val_loader:\n                batch = batch[0].to(self.device, non_blocking=self.device.type == 'cuda')\n                loss = self.flow.forward_kld(batch) #loss_fn(self.flow, batch)\n                l2_reg = l2_regularization(self.flow, lambdaL2) if lambdaL2 else 0\n                loss = loss + l2_reg\n                if ~(torch.isnan(loss) | torch.isinf(loss)):\n                    val_loss += loss.item()\n                    Nbatches += 1\n                # else:\n                #     breakpoint()\n        return val_loss / max(1, Nbatches)\n\n    def _log_epoch(self, epoch, train_loss, val_loss, epochs_losses, train_losses, val_losses, target_distribution, savepath):\n        \"\"\"\n        Log the training and validation losses for the epoch.\n\n        Args:\n            epoch (int): The current epoch.\n            train_loss (float): The training loss for the epoch.\n            val_loss (float): The validation loss for the epoch.\n            epochs_losses (list): List of epochs.\n            train_losses (list): List of training losses.\n            val_losses (list): List of validation losses.\n            target_distribution (np.ndarray): The target distribution for diagnostics.\n            savepath (str): The path to save the diagnostics.\n        \"\"\"\n\n        if val_loss is not None:\n            logging.info(f'Epoch {epoch}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n        else:\n            logging.info(f'Epoch {epoch}, Train Loss: {train_loss}')\n\n        epochs_losses.append(epoch)\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n\n        self._save_diagnostics(epochs_losses, train_losses, val_losses, target_distribution, savepath)\n\n    def _save_model(self, epochs, optimizer, scheduler, trainedpath):\n        \"\"\"\n        Save the trained model.\n\n        Args:\n            epochs (int): The number of epochs trained.\n            optimizer (torch.optim.Optimizer): The optimizer used for training.\n            scheduler (torch.optim.lr_scheduler): The learning rate scheduler.\n            trainedpath (str): The path to save the trained model.\n        \"\"\"\n\n        savedict = {\n            'epoch': epochs,\n            'model_state_dict': self.flow.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n        }\n        torch.save(savedict, trainedpath)\n\n    def _save_diagnostics(self, epochs_losses, train_losses, val_losses, target_distribution, savepath, ndim=10):\n        \"\"\"\n        Save diagnostics for the trained model.\n\n        Args:\n            epochs_losses (list): List of epochs.\n            train_losses (list): List of training losses.\n            val_losses (list): List of validation losses.\n            target_distribution (np.ndarray): The target distribution for diagnostics.\n            savepath (str): The path to save the diagnostics.\n            ndim (int, optional): The number of dimensions to plot. Defaults to 10.\n        \"\"\"\n        Nsamples_default = int(1e4)\n        Nsamples = target_distribution.shape[0] if target_distribution is not None else Nsamples_default\n        Nsamples = min(Nsamples, Nsamples_default)\n\n        samples_here, log_prob = self.flow.sample(Nsamples)\n        samples_here = samples_here.cpu().detach().numpy()\n\n        lossplot(epochs_losses, train_losses, val_losses, plot_dir=savepath, savename='flow_loss')\n        try:\n            cornerplot_training(samples_here[:, :ndim], target_distribution[:, :ndim], epoch=epochs_losses[-1], plot_dir=savepath, savename=f'flow_cornerplot')\n        except Exception as e:\n            logging.error(f\"Error plotting cornerplot: {e}\")\n\n        logging.debug(\"Diagnostics saved\")\n\n    def load(self, path: str = './', filename: str = 'trainedflow.pth'):\n        \"\"\"\n        Load a trained flow model from the specified path.\n\n        Args:\n            path (str, optional): The path to the saved model. Defaults to './'.\n            filename (str, optional): The filename of the saved model. Defaults to 'trainedflow.pth'.\n        \"\"\"\n\n        try:\n            loadpath = path + filename\n            logging.debug(f\"Loading flow from {loadpath}\")\n            checkpoint = torch.load(loadpath)\n            self.flow.load_state_dict(checkpoint['model_state_dict'])\n            logging.debug(\"Flow loaded\")\n            return True\n        except Exception as e:\n            logging.error(f\"Error loading flow: {e}\")\n            return False\n</code></pre>"},{"location":"api/core/#flowevidence.core.FlowContainer.build_flow","title":"<code>build_flow(num_dims, num_flow_steps=16, transform_type='nvp', transform_kwargs={})</code>","text":"<p>Builds the flow model using the specified parameters. This method initializes the flow model by calling the <code>get_flow</code> function with the  number of dimensions, number of flow steps, type of transformation, and device to be used for computation.</p> <p>Parameters:</p> Name Type Description Default <code>num_dims</code> <code>int</code> <p>The number of dimensions for the flow model.</p> required <code>num_flow_steps</code> <code>int</code> <p>The number of flow steps in the model. Default is 16.</p> <code>16</code> <code>transform_type</code> <code>str</code> <p>The type of transformation to use. Default is 'nvp'.</p> <code>'nvp'</code> <code>transform_kwargs</code> <code>dict</code> <p>Additional keyword arguments for the transformation. Default is {}.</p> <code>{}</code> Source code in <code>flowevidence/core.py</code> <pre><code>def build_flow(self, \n               num_dims: int,\n               num_flow_steps: int = 16,\n               transform_type: str = 'nvp',\n               transform_kwargs: dict = {},\n               ):\n    \"\"\"\n    Builds the flow model using the specified parameters.\n    This method initializes the flow model by calling the `get_flow` function with the \n    number of dimensions, number of flow steps, type of transformation, and device to be used for computation.\n\n    Args:  \n        num_dims (int): The number of dimensions for the flow model.\n        num_flow_steps (int): The number of flow steps in the model. Default is 16.\n        transform_type (str): The type of transformation to use. Default is 'nvp'.\n        transform_kwargs (dict): Additional keyword arguments for the transformation. Default is {}.\n    \"\"\"\n\n    self.flow = get_flow(num_dims, \n                        num_flow_steps=num_flow_steps, \n                        transform_type=transform_type,\n                        transform_kwargs=transform_kwargs,\n                        device=self.device\n                        )\n</code></pre>"},{"location":"api/core/#flowevidence.core.FlowContainer.load","title":"<code>load(path='./', filename='trainedflow.pth')</code>","text":"<p>Load a trained flow model from the specified path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the saved model. Defaults to './'.</p> <code>'./'</code> <code>filename</code> <code>str</code> <p>The filename of the saved model. Defaults to 'trainedflow.pth'.</p> <code>'trainedflow.pth'</code> Source code in <code>flowevidence/core.py</code> <pre><code>def load(self, path: str = './', filename: str = 'trainedflow.pth'):\n    \"\"\"\n    Load a trained flow model from the specified path.\n\n    Args:\n        path (str, optional): The path to the saved model. Defaults to './'.\n        filename (str, optional): The filename of the saved model. Defaults to 'trainedflow.pth'.\n    \"\"\"\n\n    try:\n        loadpath = path + filename\n        logging.debug(f\"Loading flow from {loadpath}\")\n        checkpoint = torch.load(loadpath)\n        self.flow.load_state_dict(checkpoint['model_state_dict'])\n        logging.debug(\"Flow loaded\")\n        return True\n    except Exception as e:\n        logging.error(f\"Error loading flow: {e}\")\n        return False\n</code></pre>"},{"location":"api/core/#flowevidence.core.FlowContainer.load_data","title":"<code>load_data(train_loader, val_loader=None)</code>","text":"<p>Loads the training and validation data loaders.</p> <p>Parameters:</p> Name Type Description Default <code>train_loader</code> <code>DataLoader</code> <p>Training data loader.</p> required <code>val_loader</code> <code>DataLoader</code> <p>Validation data loader. Default is None.</p> <code>None</code> Source code in <code>flowevidence/core.py</code> <pre><code>def load_data(self, train_loader: DataLoader, val_loader: Optional[DataLoader] = None):\n    \"\"\"\n    Loads the training and validation data loaders.\n\n    Args:\n        train_loader (DataLoader): Training data loader.\n        val_loader (DataLoader, optional): Validation data loader. Default is None.\n    \"\"\"\n    self.train_loader = train_loader\n    self.val_loader = val_loader\n</code></pre>"},{"location":"api/core/#flowevidence.core.FlowContainer.train","title":"<code>train(start_epoch=0, epochs=1000, lr=0.001, weight_decay=0.0, lambdaL2=None, early_stopping=False, stopping_kwargs={}, path='./', filename='trainedflow.pth', target_distribution=None)</code>","text":"<p>Train the flow model.</p> <p>Parameters:</p> Name Type Description Default <code>start_epoch</code> <code>int</code> <p>The starting epoch for training. Defaults to 0.</p> <code>0</code> <code>epochs</code> <code>int</code> <p>The number of epochs to train the model. Defaults to 1000.</p> <code>1000</code> <code>lr</code> <code>float</code> <p>The learning rate for the optimizer. Defaults to 1e-3.</p> <code>0.001</code> <code>weight_decay</code> <code>float</code> <p>The weight decay for the optimizer. Defaults to 0.0.</p> <code>0.0</code> <code>lambdaL2</code> <code>Optional[float]</code> <p>The L2 regularization parameter. Defaults to None.</p> <code>None</code> <code>early_stopping</code> <code>Optional[bool]</code> <p>Whether to use early stopping. Defaults to False.</p> <code>False</code> <code>stopping_kwargs</code> <code>Optional[dict]</code> <p>Keyword arguments for early stopping. Defaults to {}.</p> <code>{}</code> <code>path</code> <code>str</code> <p>The path to save the trained model and diagnostics. Defaults to './'.</p> <code>'./'</code> <code>filename</code> <code>str</code> <p>The filename for the saved model. Defaults to 'trainedflow.pth'.</p> <code>'trainedflow.pth'</code> <code>target_distribution</code> <code>Optional[ndarray]</code> <p>The target distribution for diagnostics. Defaults to None.</p> <code>None</code> Source code in <code>flowevidence/core.py</code> <pre><code>def train(self, \n          start_epoch: int = 0, \n          epochs: int = 1000, \n          lr: float = 1e-3, \n          weight_decay: float = 0.0,\n          lambdaL2: Optional[float] = None,\n          early_stopping: bool | Callable = False,\n          stopping_kwargs: Optional[dict] = {},\n          path: str = './', \n          filename: str = 'trainedflow.pth', \n          target_distribution: Optional[np.ndarray] = None\n          ):\n    \"\"\"\n    Train the flow model.\n\n    Args:\n        start_epoch (int, optional): The starting epoch for training. Defaults to 0.\n        epochs (int, optional): The number of epochs to train the model. Defaults to 1000.\n        lr (float, optional): The learning rate for the optimizer. Defaults to 1e-3.\n        weight_decay (float, optional): The weight decay for the optimizer. Defaults to 0.0.\n        lambdaL2 (Optional[float], optional): The L2 regularization parameter. Defaults to None.\n        early_stopping (Optional[bool], optional): Whether to use early stopping. Defaults to False.\n        stopping_kwargs (Optional[dict], optional): Keyword arguments for early stopping. Defaults to {}.\n        path (str, optional): The path to save the trained model and diagnostics. Defaults to './'.\n        filename (str, optional): The filename for the saved model. Defaults to 'trainedflow.pth'.\n        target_distribution (Optional[np.ndarray], optional): The target distribution for diagnostics. Defaults to None.\n    \"\"\"\n\n    logging.info(\"Training flow for {} epochs\".format(epochs - start_epoch))\n\n    optimizer = torch.optim.Adam(self.flow.parameters(), lr=lr, weight_decay=weight_decay)\n    if self.val_loader:\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                            factor=0.5,\n                                                            patience=100,\n                                                            threshold=1e-4)\n\n    else:\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n\n    current_lr = lr\n\n    epochs_losses = []\n    train_losses = []\n    val_losses = []\n\n    stopping_fn = None\n    converged = False\n    if isinstance(early_stopping, bool) and early_stopping:\n        stopping_fn = EarlyStopping(**stopping_kwargs)\n    elif isinstance(early_stopping, Callable):\n        stopping_fn = early_stopping\n\n    else:\n        logging.info(\"Early stopping disabled\")\n\n    trainedpath = path + filename\n    savepath = path + \"diagnostic/\"\n    os.makedirs(savepath, exist_ok=True)\n\n    logging.info(\"Training started\")\n    logging.info(f\"Saving diagnostics to {savepath}\")\n\n    if epochs &lt; start_epoch:\n        logging.info(\"Resuming training\")\n        epochs = start_epoch + epochs\n\n    epoch_iterator = tqdm(range(start_epoch, epochs), desc=\"Training\", disable=not self.verbose)\n\n    for epoch in epoch_iterator:\n        train_loss = self._train_one_epoch(optimizer, lambdaL2)\n        val_loss = self._validate_one_epoch(lambdaL2) if self.val_loader else None\n        scheduler.step(val_loss) if self.val_loader else scheduler.step()\n\n\n        if stopping_fn:\n            if stopping_fn(val_loss):\n                logging.info(f\"Early stopping at epoch {epoch}\")\n                converged = True\n                break\n\n        if epoch  &gt; 0 and epoch % 100 == 0:\n            if self.verbose:\n                self._log_epoch(epoch, train_loss, val_loss, epochs_losses, train_losses, val_losses, target_distribution, savepath)\n                if scheduler.get_last_lr()[0] != current_lr:\n                    current_lr = scheduler.get_last_lr()[0]\n                    logging.info(f\"New learning rate: {scheduler.get_last_lr()[0]}\")\n                logging.info(\"Saving model @ epoch {}\".format(epoch))\n\n            self._save_model(epoch, optimizer, scheduler, trainedpath)\n\n    if stopping_fn and not converged:\n        logging.warning(\"Early stopping did not trigger\")\n\n    self._save_model(epochs, optimizer, scheduler, trainedpath)\n    logging.debug(\"Training finished\")\n\n    logging.debug(\"Saving diagnostics\")\n    epochs_losses.append(epoch)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    self._save_diagnostics(epochs_losses, train_losses, val_losses, target_distribution, savepath)\n</code></pre>"},{"location":"api/core/#flowevidence.core.EarlyStopping","title":"<code>EarlyStopping</code>","text":"<p>Early stopping class to stop training the flow model when the validation loss does not improve.</p> <p>Parameters:</p> Name Type Description Default <code>patience</code> <code>int</code> <p>Number of epochs to wait before stopping training. Default is 50.</p> <code>50</code> <code>delta</code> <code>float</code> <p>Minimum change in the monitored quantity to qualify as an improvement. Default is 1e-6.</p> <code>0.0001</code> <p>Methods:</p> Name Description <code>__call__</code> <p>Checks if the validation loss has improved.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>class EarlyStopping:\n    \"\"\"\n    Early stopping class to stop training the flow model when the validation loss does not improve.\n\n    Args:\n        patience (int): Number of epochs to wait before stopping training. Default is 50.\n        delta (float): Minimum change in the monitored quantity to qualify as an improvement. Default is 1e-6.\n\n    Methods:\n        __call__(val_loss):\n            Checks if the validation loss has improved.\n    \"\"\"\n\n    def __init__(self, patience: int = 50, delta: float = 1e-4):\n        self.patience = patience\n        self.delta = delta\n        self.counter = 0\n        self.best_loss = float('inf')\n        self.early_stop = False\n\n    def __call__(self, val_loss: float):\n        \"\"\"\n        Checks if the validation loss has improved.\n\n        Args:\n            val_loss (float): The validation loss to check.\n\n        Returns:\n            stop (bool): True if the validation loss has not improved for the specified number of epochs, False otherwise.\n        \"\"\"\n\n        if np.abs(val_loss - self.best_loss) &lt; self.delta:\n            self.counter += 1\n            if self.counter &gt;= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.counter = 0\n\n        return self.early_stop\n</code></pre>"},{"location":"api/core/#flowevidence.core.EarlyStopping.__call__","title":"<code>__call__(val_loss)</code>","text":"<p>Checks if the validation loss has improved.</p> <p>Parameters:</p> Name Type Description Default <code>val_loss</code> <code>float</code> <p>The validation loss to check.</p> required <p>Returns:</p> Name Type Description <code>stop</code> <code>bool</code> <p>True if the validation loss has not improved for the specified number of epochs, False otherwise.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def __call__(self, val_loss: float):\n    \"\"\"\n    Checks if the validation loss has improved.\n\n    Args:\n        val_loss (float): The validation loss to check.\n\n    Returns:\n        stop (bool): True if the validation loss has not improved for the specified number of epochs, False otherwise.\n    \"\"\"\n\n    if np.abs(val_loss - self.best_loss) &lt; self.delta:\n        self.counter += 1\n        if self.counter &gt;= self.patience:\n            self.early_stop = True\n    else:\n        self.best_loss = val_loss\n        self.counter = 0\n\n    return self.early_stop\n</code></pre>"},{"location":"api/core/#flowevidence.core.EvidenceFlow","title":"<code>EvidenceFlow</code>","text":"<p>               Bases: <code>FlowContainer</code></p> <p>A class for computing the log evidence (logZ) using a trained flow model and the posterior values associated with MCMC samples.</p> <p>Parameters:</p> Name Type Description Default <code>posterior_samples</code> <code>ndarray or dict</code> <p>The posterior samples to use for training the flow model. If a dictionary, the values are concatenated along the last axis.</p> <code>None</code> <code>logposterior_values</code> <code>ndarray</code> <p>The log posterior values associated with the posterior samples.</p> <code>None</code> <code>num_flow_steps</code> <code>int</code> <p>Number of flow steps in the model. Default is 16.</p> <code>16</code> <code>transform_type</code> <code>str</code> <p>The type of transformation to use. Default is 'nvp'.</p> <code>'nvp'</code> <code>transform_kwargs</code> <code>dict</code> <p>Additional keyword arguments for the transformation. Default is {}.</p> <code>{}</code> <code>device</code> <code>str or device</code> <p>Device to run the model on. Default is 'cpu'.</p> <code>'cpu'</code> <code>verbose</code> <code>bool</code> <p>Whether to print verbose output during training. Default is False.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>Data type for tensors. Default is torch.float64.</p> <code>float64</code> <code>Nbatches</code> <code>int</code> <p>Number of batches. Default is 1.</p> <code>1</code> <code>split_ratio</code> <code>float</code> <p>Ratio to split data into training and validation sets. Default is 0.8.</p> <code>0.8</code> <code>conversion_method</code> <code>str</code> <p>Method for data conversion to the flow latent space ('normalize_minmax' or 'normalize_gaussian').                       Default is 'normalize_minmax'.    </p> <code>'minmax'</code> <code>autoencoder</code> <code>Module</code> <p>An autoencoder to encode the training and validation samples. Default is None.</p> <code>None</code> <code>train_autoencoder_kwargs</code> <code>dict</code> <p>Keyword arguments for training the autoencoder. Default is {}.</p> <code>{}</code> <p>Methods:</p> Name Description <code>_setup_conversions</code> <p>Sets up the conversion methods to the latent space.</p> <code>_process_posterior_samples</code> <p>Processes the posterior samples and converts them to tensors.</p> <code>_process_tensors</code> <p>Processes tensors, shuffles samples, splits data, and creates data loaders.</p> <code>get_logZ</code> <p>Computes the log evidence (logZ) by building and training the flow model if necessary.</p> Source code in <code>flowevidence/core.py</code> <pre><code>class EvidenceFlow(FlowContainer):\n    \"\"\"\n    A class for computing the log evidence (logZ) using a trained flow model and the posterior values associated with MCMC samples.\n\n    Args:\n        posterior_samples (np.ndarray or dict): The posterior samples to use for training the flow model. If a dictionary, the values are concatenated along the last axis.\n        logposterior_values (np.ndarray): The log posterior values associated with the posterior samples.\n        num_flow_steps (int): Number of flow steps in the model. Default is 16.\n        transform_type (str): The type of transformation to use. Default is 'nvp'.\n        transform_kwargs (dict): Additional keyword arguments for the transformation. Default is {}.\n        device (str or torch.device): Device to run the model on. Default is 'cpu'.\n        verbose (bool): Whether to print verbose output during training. Default is False.\n        dtype (torch.dtype): Data type for tensors. Default is torch.float64.\n        Nbatches (int): Number of batches. Default is 1.\n        split_ratio (float): Ratio to split data into training and validation sets. Default is 0.8.\n        conversion_method (str): Method for data conversion to the flow latent space ('normalize_minmax' or 'normalize_gaussian'). \n                                 Default is 'normalize_minmax'.    \n        autoencoder (nn.Module): An autoencoder to encode the training and validation samples. Default is None.\n        train_autoencoder_kwargs (dict): Keyword arguments for training the autoencoder. Default is {}.\n\n    Methods:\n        _setup_conversions(conversion_method):\n            Sets up the conversion methods to the latent space.\n        _process_posterior_samples(posterior_samples):\n            Processes the posterior samples and converts them to tensors.\n        _process_tensors():\n            Processes tensors, shuffles samples, splits data, and creates data loaders.\n        get_logZ(load_kwargs={}, train_kwargs={}):\n            Computes the log evidence (logZ) by building and training the flow model if necessary.\n    \"\"\"\n\n    def __init__(self, \n                 posterior_samples: np.ndarray | dict = None,\n                 logposterior_values: np.ndarray = None,\n                 num_flow_steps: int = 16, \n                 transform_type: str = 'nvp',\n                 transform_kwargs: dict = {},\n                 device: str | torch.device = 'cpu', \n                 verbose: bool = False,\n                 dtype: torch.dtype = torch.float64,\n                 Nbatches: int = 1,\n                 split_ratio: float = 0.8,\n                 conversion_method: str = 'minmax',\n                 autoencoder: nn.Module = None,\n                 train_autoencoder_kwargs: dict = {},\n                 ):\n\n        super().__init__(device, dtype, verbose)\n\n        self.num_flow_steps = num_flow_steps\n        self.transform_type = transform_type\n        self.transform_kwargs = transform_kwargs\n\n        self.split_ratio = split_ratio\n        self._setup_conversions(conversion_method)\n        self.posterior_samples = self._process_posterior_samples(posterior_samples)\n\n        self.Nsamples, self.num_dims_full = self.posterior_samples.shape\n        self.Nbatches = Nbatches if Nbatches &lt; self.Nsamples else self.Nsamples\n        self.batch_size = self.Nsamples // self.Nbatches\n        self.logposterior_values = logposterior_values\n\n        # Autoencoder\n        self.autoencoder = autoencoder\n        self.train_autoencoder_kwargs = train_autoencoder_kwargs\n\n        self._process_tensors()\n        self.num_dims = self.latent_target.shape[1]\n\n    def _setup_conversions(self, conversion_method):\n        \"\"\"\n        Sets up the conversion methods for transforming data to and from latent space.\n\n        Args:\n            conversion_method (str): The method to use for conversion. Must be one of 'normalize_minmax' or 'normalize_gaussian'.\n\n        Raises:\n            ValueError: If an invalid conversion method is provided.\n        \"\"\"\n\n        allowed_methods = {\n        'minmax': (normalize_minmax, denormalize_minmax),\n        'gaussian': (normalize_gaussian, normalize_gaussian),\n        'sigmoid': (normalize_sigmoid, denormalize_sigmoid),\n        #'logit': (normalize_logit, denormalize_logit)\n    }\n\n        if conversion_method in allowed_methods:\n            self._to_latent_space, self._from_latent_space = allowed_methods[conversion_method]\n        else:\n            raise ValueError(f\"Invalid conversion method: {conversion_method}. Choose from {list(allowed_methods.keys())}\")\n\n    def _process_posterior_samples(self, posterior_samples):\n        \"\"\"\n        Processes posterior samples by concatenating them if they are in dictionary form \n        and converting them to a PyTorch tensor.\n\n        Args:\n            posterior_samples (dict or array-like): The posterior samples to process. \n                If a dictionary, the values are concatenated along the last axis.\n\n        Returns:\n            torch.Tensor: The processed posterior samples as a PyTorch tensor.\n        \"\"\"\n\n        if isinstance(posterior_samples, dict):\n            posterior_samples = np.concatenate([posterior_samples[key] for key in posterior_samples.keys()], axis=-1)\n        posterior_samples = torch.tensor(posterior_samples, dtype=self.dtype)\n        return posterior_samples\n\n    def _process_tensors(self):\n        \"\"\"\n        Processes the posterior samples by converting them to latent space, shuffling, \n        splitting into training and validation sets, and creating data loaders.\n        This method performs the following steps:\n        1. Converts posterior samples to latent space.\n        2. Shuffles the latent samples.\n        3. Splits the shuffled samples into training and validation sets based on the split ratio.\n        4. Creates data loaders for the training and validation sets.\n        5. Loads the data using the created data loaders.\n        6. If an autoencoder is provided, it is used to encode the training and validation samples.        \n\n        Attributes:\n            self.q1: The first component of the latent space representation.\n            self.q2: The second component of the latent space representation.\n            self.latent_target: The latent space representation of the posterior samples as a NumPy array.\n        \"\"\"\n\n        latent_samples, self.q1, self.q2 = self._to_latent_space(self.posterior_samples)\n        self.latent_target = latent_samples.to(self.device)\n        #breakpoint()\n\n        shuffled_samples = shuffle(latent_samples)\n        if self.split_ratio:\n            train_samples, val_samples = split(shuffled_samples, self.split_ratio)\n        else:\n            train_samples, val_samples = shuffled_samples, None\n\n        train_loader, val_loader = create_data_loaders(train_samples, val_samples, batch_size=self.batch_size, num_workers=0, pin_memory=self.device.type == 'cuda')\n\n        if self.autoencoder:\n            self._sanity_check_autoencoder(train_loader, val_loader, self.train_autoencoder_kwargs)\n            train_samples, val_samples = self._encode_tensors(train_samples, val_samples)\n            train_loader, val_loader = create_data_loaders(train_samples, val_samples, batch_size=self.batch_size, num_workers=0, pin_memory=self.device.type == 'cuda')\n\n        self.load_data(train_loader, val_loader)\n\n    def _sanity_check_autoencoder(self, \n                                  train_loader: DataLoader, \n                                  val_loader: DataLoader,\n                                  training_kwargs: dict\n                                  ):\n        \"\"\"\n        Checks if the autoencoder is trained and trains it if necessary.\n\n        Args:\n            train_loader (DataLoader): The training samples to train the autoencoder on.\n            val_loader (DataLoader): The validation samples to train the autoencoder on.\n            training_kwargs (dict): Keyword arguments for training the autoencoder.\n        \"\"\"\n\n        filename = self.train_autoencoder_kwargs.get('filename', 'autoencoder.pth')\n        if os.path.exists(training_kwargs['path'] + filename):\n            logging.info(\"Loading autoencoder\")\n            self.autoencoder.load_model(path=training_kwargs['path'] + filename)\n        else:\n            logging.info(\"Autoencoder not found\")\n\n        if self.autoencoder.trained:\n            # check if autoencoder is trained. If not, train it\n            logging.info(\"Autoencoder already trained\")\n        else:\n            logging.info(\"Training autoencoder\")\n            self.autoencoder.train(train_loader, val_loader, **training_kwargs)\n            logging.info(\"Autoencoder trained\")\n\n\n    def _encode_tensors(self, \n                        train_tensor: torch.Tensor, \n                        val_tensor: Optional[torch.Tensor] = None\n                        ):\n        \"\"\"\n        Encodes the training and validation samples using the autoencoder. If the autoencoder is not trained, it will be trained. If the autoencoder is not provided, the samples are returned as is.\n\n        Args:\n            train_loader (DataLoader): The training samples to train the autoencoder on.\n            val_loader (DataLoader): The validation samples to train the autoencoder on.\n            training_kwargs (dict): Keyword arguments for training the autoencoder.\n        \"\"\"\n        train_tensor = self.autoencoder.encode(train_tensor.to(self.device)).to('cpu')\n        if val_tensor is not None:\n            val_tensor = self.autoencoder.encode(val_tensor.to(self.device)).to('cpu')\n        self.latent_target = self.autoencoder.encode(self.latent_target)\n\n        return train_tensor, val_tensor\n\n\n    def get_logZ(self,\n                 load_kwargs: dict = {},\n                 train_kwargs: dict = {},\n                 ): \n        \"\"\"\n        Computes the log evidence (logZ) by building and training the flow model if necessary.\n\n        Args:\n            load_kwargs (dict): Keyword arguments for loading the flow model.\n            train_kwargs (dict): Keyword arguments for training the flow model.\n\n        Returns:\n            logZ (float): The mean log evidence.\n            dlogZ (float): The standard deviation of the log evidence.\n        \"\"\"\n        self._sanity_check_flow(load_kwargs, train_kwargs)\n\n        logProb = self.flow.log_prob(self.latent_target).cpu().detach().numpy()\n        logZ = self.logposterior_values - logProb\n        mean, std = np.mean(logZ), np.std(logZ)\n        logging.debug(f\"LogZ: {mean} +/- {std}\")\n\n        return mean, std\n\n    def get_draws(self, \n                  load_kwargs: dict = {}, \n                  train_kwargs: dict = {}, \n                  num_draws: int = 10000\n                  ):\n        \"\"\"\n        Draw samples from the trained flow model. If no model is loaded or trained, it will be trained.\n\n        Args:\n            load_kwargs (dict): Keyword arguments for loading the flow model. Refer to the documentation for the `load` method.\n            train_kwargs (dict): Keyword arguments for training the flow model. Refer to the documentation for the `train` method.\n            num_draws (int, optional): The number of samples to draw. Defaults to 10000.\n\n        Returns:\n            samples (np.ndarray): The drawn samples transformed in the original space.\n        \"\"\"\n        self._sanity_check_flow(load_kwargs, train_kwargs)\n        samples, log_prob = self.flow.sample(num_draws).cpu().detach().numpy()\n\n        if self.autoencoder:\n            samples = self.autoencoder.decode(samples)\n\n        converted = self._from_latent_space(samples, self.q1, self.q2)\n\n        return converted\n\n    def _sanity_check_flow(self, \n                           load_kwargs: dict = {}, \n                           train_kwargs: dict = {}\n                           ):\n        \"\"\"\n        Checks if the flow model is loaded or trained and loads or trains it if necessary.\n\n        Args:\n            load_kwargs (dict): Keyword arguments for loading the flow model. Refer to the documentation for the `load` method.\n            train_kwargs (dict): Keyword arguments for training the flow model. Refer to the documentation for the `train` method.\n        \"\"\"\n        if not hasattr(self, 'flow'):\n            logging.info(\"Building flow\")\n            self.build_flow(self.num_dims, self.num_flow_steps, self.transform_type, self.transform_kwargs)\n\n        load = self.load(**load_kwargs)\n        train_kwargs_here = train_kwargs.copy()\n\n        if not load:\n            train_kwargs_here['target_distribution'] = self.latent_target.cpu().detach().numpy()\n            if 'path' not in train_kwargs_here and 'path' in load_kwargs:\n                train_kwargs_here['path'] = load_kwargs['path']\n\n            if 'filename' not in train_kwargs_here and 'filename' in load_kwargs:\n                train_kwargs_here['filename'] = load_kwargs['filename']\n\n            logging.info(\"Training flow\")\n            self.train(**train_kwargs_here)\n</code></pre>"},{"location":"api/core/#flowevidence.core.EvidenceFlow.get_draws","title":"<code>get_draws(load_kwargs={}, train_kwargs={}, num_draws=10000)</code>","text":"<p>Draw samples from the trained flow model. If no model is loaded or trained, it will be trained.</p> <p>Parameters:</p> Name Type Description Default <code>load_kwargs</code> <code>dict</code> <p>Keyword arguments for loading the flow model. Refer to the documentation for the <code>load</code> method.</p> <code>{}</code> <code>train_kwargs</code> <code>dict</code> <p>Keyword arguments for training the flow model. Refer to the documentation for the <code>train</code> method.</p> <code>{}</code> <code>num_draws</code> <code>int</code> <p>The number of samples to draw. Defaults to 10000.</p> <code>10000</code> <p>Returns:</p> Name Type Description <code>samples</code> <code>ndarray</code> <p>The drawn samples transformed in the original space.</p> Source code in <code>flowevidence/core.py</code> <pre><code>def get_draws(self, \n              load_kwargs: dict = {}, \n              train_kwargs: dict = {}, \n              num_draws: int = 10000\n              ):\n    \"\"\"\n    Draw samples from the trained flow model. If no model is loaded or trained, it will be trained.\n\n    Args:\n        load_kwargs (dict): Keyword arguments for loading the flow model. Refer to the documentation for the `load` method.\n        train_kwargs (dict): Keyword arguments for training the flow model. Refer to the documentation for the `train` method.\n        num_draws (int, optional): The number of samples to draw. Defaults to 10000.\n\n    Returns:\n        samples (np.ndarray): The drawn samples transformed in the original space.\n    \"\"\"\n    self._sanity_check_flow(load_kwargs, train_kwargs)\n    samples, log_prob = self.flow.sample(num_draws).cpu().detach().numpy()\n\n    if self.autoencoder:\n        samples = self.autoencoder.decode(samples)\n\n    converted = self._from_latent_space(samples, self.q1, self.q2)\n\n    return converted\n</code></pre>"},{"location":"api/core/#flowevidence.core.EvidenceFlow.get_logZ","title":"<code>get_logZ(load_kwargs={}, train_kwargs={})</code>","text":"<p>Computes the log evidence (logZ) by building and training the flow model if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>load_kwargs</code> <code>dict</code> <p>Keyword arguments for loading the flow model.</p> <code>{}</code> <code>train_kwargs</code> <code>dict</code> <p>Keyword arguments for training the flow model.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>logZ</code> <code>float</code> <p>The mean log evidence.</p> <code>dlogZ</code> <code>float</code> <p>The standard deviation of the log evidence.</p> Source code in <code>flowevidence/core.py</code> <pre><code>def get_logZ(self,\n             load_kwargs: dict = {},\n             train_kwargs: dict = {},\n             ): \n    \"\"\"\n    Computes the log evidence (logZ) by building and training the flow model if necessary.\n\n    Args:\n        load_kwargs (dict): Keyword arguments for loading the flow model.\n        train_kwargs (dict): Keyword arguments for training the flow model.\n\n    Returns:\n        logZ (float): The mean log evidence.\n        dlogZ (float): The standard deviation of the log evidence.\n    \"\"\"\n    self._sanity_check_flow(load_kwargs, train_kwargs)\n\n    logProb = self.flow.log_prob(self.latent_target).cpu().detach().numpy()\n    logZ = self.logposterior_values - logProb\n    mean, std = np.mean(logZ), np.std(logZ)\n    logging.debug(f\"LogZ: {mean} +/- {std}\")\n\n    return mean, std\n</code></pre>"},{"location":"api/core/#flowevidence.core.ErynEvidenceFlow","title":"<code>ErynEvidenceFlow</code>","text":"<p>               Bases: <code>EvidenceFlow</code></p> <p>Wrapper class for using the <code>EvidenceFlow</code> class directly with a backend from the <code>Eryn</code> mcmc sampler.  It stores the samples and logP values in a file for faster loading.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>str or HDFBackend</code> <p>The backend to load the samples from.</p> <code>None</code> <code>loader</code> <code>SamplesLoader</code> <p>A pysco.eryn.SamplesLoader object to load the samples from.</p> <code>None</code> <code>samples_file</code> <code>str</code> <p>The file to save the samples and logP values to. Default is './samples.h5'.</p> <code>'./samples.h5'</code> <code>ess</code> <code>int</code> <p>The effective sample size. Default is 1e4. It is used to compute the number of samples to discard and thin if they are <code>None</code>.</p> <code>int(10000.0)</code> <code>discard</code> <code>int</code> <p>The number of samples to discard. Default is None.</p> <code>None</code> <code>thin</code> <code>int</code> <p>The thinning factor. Default is None.</p> <code>None</code> <code>leaves_to_ndim</code> <code>bool</code> <p>Whether to reshape the leaves to ndim. Default is False.</p> <code>False</code> <code>num_flow_steps</code> <code>int</code> <p>Number of flow steps in the model. Default is 16.</p> <code>16</code> <code>transform_type</code> <code>str</code> <p>The type of transformation to use. Default is 'nvp'.</p> <code>'nvp'</code> <code>transform_kwargs</code> <code>dict</code> <p>Additional keyword arguments for the transformation. Default is {}.</p> <code>{}</code> <code>device</code> <code>str or device</code> <p>Device to run the model on. Default is 'cpu'.</p> <code>'cpu'</code> <code>verbose</code> <code>bool</code> <p>Whether to print verbose output during training. Default is False.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>Data type for tensors. Default is torch.float64.</p> <code>float64</code> <code>Nbatches</code> <code>int</code> <p>Number of batches. Default is 1.</p> <code>1</code> <code>split_ratio</code> <code>float</code> <p>Ratio to split data into training and validation sets. Default is 0.8.</p> <code>0.8</code> <code>conversion_method</code> <code>str</code> <p>Method for data conversion to the flow latent space ('normalize_minmax' or 'normalize_gaussian'). Default is 'normalize_minmax'.</p> <code>'normalize_minmax'</code> <code>autoencoder</code> <code>Module</code> <p>An autoencoder to encode the training and validation samples. Default is None.</p> <code>None</code> <code>train_autoencoder_kwargs</code> <code>dict</code> <p>Keyword arguments for training the autoencoder. Default is {}.</p> <code>{}</code> Source code in <code>flowevidence/core.py</code> <pre><code>class ErynEvidenceFlow(EvidenceFlow):\n    \"\"\"\n    Wrapper class for using the ``EvidenceFlow`` class directly with a backend from the ``Eryn`` mcmc sampler. \n    It stores the samples and logP values in a file for faster loading.\n\n    Args:\n        backend (str or HDFBackend): The backend to load the samples from.\n        loader (SamplesLoader): A pysco.eryn.SamplesLoader object to load the samples from.\n        samples_file (str): The file to save the samples and logP values to. Default is './samples.h5'.\n        ess (int): The effective sample size. Default is 1e4. It is used to compute the number of samples to discard and thin if they are `None`.\n        discard (int): The number of samples to discard. Default is None.\n        thin (int): The thinning factor. Default is None.\n        leaves_to_ndim (bool): Whether to reshape the leaves to ndim. Default is False.\n        num_flow_steps (int): Number of flow steps in the model. Default is 16.\n        transform_type (str): The type of transformation to use. Default is 'nvp'.\n        transform_kwargs (dict): Additional keyword arguments for the transformation. Default is {}.\n        device (str or torch.device): Device to run the model on. Default is 'cpu'.\n        verbose (bool): Whether to print verbose output during training. Default is False.\n        dtype (torch.dtype): Data type for tensors. Default is torch.float64.\n        Nbatches (int): Number of batches. Default is 1.\n        split_ratio (float): Ratio to split data into training and validation sets. Default is 0.8.\n        conversion_method (str): Method for data conversion to the flow latent space ('normalize_minmax' or 'normalize_gaussian'). Default is 'normalize_minmax'.\n        autoencoder (nn.Module): An autoencoder to encode the training and validation samples. Default is None.\n        train_autoencoder_kwargs (dict): Keyword arguments for training the autoencoder. Default is {}.\n    \"\"\"\n\n    def __init__(self,\n                backend: str | HDFBackend = None,\n                loader: SamplesLoader = None,\n                samples_file: h5py.File = './samples.h5',\n                ess: int = int(1e4),\n                discard: int = None,\n                thin: int = None,\n                leaves_to_ndim: bool = False,\n                num_flow_steps: int = 16, \n                transform_type: str = 'nvp',\n                transform_kwargs: dict = {},\n                device: str | torch.device = 'cpu', \n                verbose: bool = False,\n                dtype: torch.dtype = torch.float64,\n                Nbatches: int = 1,\n                split_ratio: float = 0.8,\n                conversion_method: str = 'normalize_minmax',\n                autoencoder: nn.Module = None,\n                train_autoencoder_kwargs: dict = {}):\n\n        if not eryn_here:\n            raise ImportError(\"Eryn is not installed. Please install Eryn to use this class, or \\\n                              use the EvidenceFlow class instead.\")\n\n        if os.path.exists(samples_file):\n            with h5py.File(samples_file, 'r') as f:\n                results = f['results']\n                samples_group = results['samples']\n                samples = {}\n                for key in samples_group.keys():\n                    samples[key] = samples_group[key][:]\n                logP = results['logP'][:]\n        else:\n            if backend is None and loader is None:\n                raise ValueError(\"Either a backend or a loader must be provided.\")\n\n            elif loader is None and backend is not None:\n                if pysco_here:\n                    loader = SamplesLoader(backend)\n                    samples, logL, logP = loader.load(ess=ess, discard=discard, thin=thin, squeeze=False, leaves_to_ndim=leaves_to_ndim)\n                else:\n                    if isinstance(backend, str):\n                        backend = HDFBackend(backend)\n\n                    samples, logP = self._load_samples_posterior(backend, ess, leaves_to_ndim=leaves_to_ndim)\n\n            else:\n                samples, logL, logP = loader.load(ess=ess, discard=discard, thin=thin, squeeze=False, leaves_to_ndim=leaves_to_ndim)\n\n            # Save the samples and logP to a file\n            os.makedirs(os.path.dirname(samples_file), exist_ok=True)\n            with h5py.File(samples_file, 'w') as f:\n                g = f.create_group('results')\n                chain = g.create_group('samples')\n                for key in samples.keys():\n                    chain.create_dataset(key, data=samples[key])\n                g.create_dataset('logP', data=logP)\n\n        super().__init__(posterior_samples=samples, \n                         logposterior_values=logP, \n                         num_flow_steps=num_flow_steps, \n                         transform_type=transform_type,\n                         transform_kwargs=transform_kwargs, \n                         device=device, \n                         verbose=verbose, \n                         dtype=dtype, \n                         Nbatches=Nbatches, \n                         split_ratio=split_ratio, \n                         conversion_method=conversion_method,\n                         autoencoder=autoencoder,\n                         train_autoencoder_kwargs=train_autoencoder_kwargs\n                         )\n\n    def _compute_discard_thin(self, \n                              samples: dict, \n                              ess: int = int(1e4)\n                              ):\n        \"\"\"\n        Compute the number of samples to discard and thin. Snippet adapted from from: `https://github.com/asantini29/pysco`\n\n        Args:\n            ess (int): Effective sample size. Default is 1e4.\n\n        Returns:    \n            discard (int): The number of samples to discard.\n            thin (int): The thinning factor.\n        \"\"\"\n\n        tau = {}\n        for name in samples.keys():\n            chain = samples[name]\n            nsteps, ntemps, nw, nleaves, ndims = chain.shape\n            chain = chain.reshape(nsteps, ntemps, nw, nleaves * ndims)\n            tau[name] = get_integrated_act(chain, average=True)\n\n        taus_all = []\n\n        for name in tau.keys():\n            tau_here = np.max(tau[name])\n            if np.isfinite(tau_here):\n                taus_all.append(tau_here)\n\n        thin = int(np.max(taus_all))\n        print(\"Number of steps: \", nsteps)\n\n        ess = int(ess)\n        N_keep = int(np.ceil(ess * self.thin / nw))\n        print(\"Number of samples to keep: \", N_keep)\n        discard = max(5000, self.backend.iteration - N_keep)\n\n        return discard, thin\n\n    def _load_samples_posterior(self, \n                                backend: HDFBackend, \n                                ess: int = None, \n                                leaves_to_ndim: bool = False\n                                ):\n        \"\"\"\n        Load the samples from the backend. If the effective sample size is provided, the number of samples to discard and thin is computed.\n        This is NOT compatible with reversible jump MCMC yet.\n\n        Args:\n            backend (HDFBackend): The backend to load the samples from.\n            ess (int, optional): The effective sample size. Defaults to None.\n            leaves_to_ndim (bool, optional): Whether to reshape the leaves to ndim. Defaults to False.\n\n        Returns:\n            samples_out (dict): The samples.\n            logP (np.ndarray): The log posterior values.\n        \"\"\"\n\n        samples = backend.get_chain()\n        samples_out = {}\n        if ess:\n            discard, thin = self._compute_discard_thin(samples, ess)\n        else:\n            discard, thin = 0, 1\n\n        for name in samples.keys():\n            ns, nt, nw, nl, nd = samples[name].shape\n            if leaves_to_ndim:\n                samples_out[name] = np.squeeze(samples[name][discard::thin, 0]).reshape(-1, nl*nd) #take the first temperature chain and flatten the rest\n            else:\n                samples_out[name] = np.squeeze(samples[name][discard::thin, 0]).reshape(-1, nd) #take the first temperature chain and flatten the rest\n\n        logP = backend.get_log_posterior(discard=discard, thin=thin)[:, 0].flatten()\n\n        return samples_out, logP\n</code></pre>"},{"location":"api/encode/","title":"API Documentation: Encode","text":""},{"location":"api/encode/#classes-to-train-and-evaluate-an-autoencoder-to-be-used-in-the-training-of-the-flow-in-this-case-the-flow-works-in-the-autoencoder-latent-space","title":"Classes to train and evaluate an autoencoder to be used in the training of the Flow. in this case, the Flow works in the autoencoder latent space.","text":""},{"location":"api/encode/#flowevidence.encode.MaskedAutoEncoder","title":"<code>MaskedAutoEncoder</code>","text":"<p>An autoencoder designed to convert samples into a latent space. The model can handle variable-dimension data,  such as RJ-MCMC branches, by using a mask to indicate \"missing\" entries at each step. This allows the compression of the RJ-MCMC samples into a fixed-size latent space that can be used to train the Flow used for the evidence calculation.</p> <p>Parameters:</p> Name Type Description Default <code>max_model_dim</code> <code>int</code> <p>Maximum dimensionality of the input data.</p> required <code>latent_dim</code> <code>int</code> <p>Dimensionality of the latent space.</p> required <code>device</code> <code>str | device</code> <p>Device to use for training. Defaults to 'cpu'.</p> <code>'cpu'</code> <code>dtype</code> <code>dtype</code> <p>Data type for the model. Defaults to torch.float64.</p> <code>float64</code> <code>use_vae</code> <code>bool</code> <p>If True, use a variational autoencoder. Defaults to False.</p> <code>False</code> <code>hidden_dim</code> <code>int</code> <p>Hidden dimension for the encoder and decoder. Defaults to 128.</p> <code>128</code> <code>dropout</code> <code>float</code> <p>Dropout rate. Defaults to 0.2.</p> <code>0.2</code> <code>verbose</code> <code>bool</code> <p>If True, print training progress. Defaults to False.</p> <code>False</code> Source code in <code>flowevidence/encode.py</code> <pre><code>class MaskedAutoEncoder:\n    \"\"\"\n    An autoencoder designed to convert samples into a latent space. The model can handle variable-dimension data, \n    such as RJ-MCMC branches, by using a mask to indicate \"missing\" entries at each step.\n    This allows the compression of the RJ-MCMC samples into a fixed-size latent space that can be used to train\n    the Flow used for the evidence calculation.\n\n    Args:\n        max_model_dim (int): Maximum dimensionality of the input data.\n        latent_dim (int): Dimensionality of the latent space.\n        device (str | torch.device, optional): Device to use for training. Defaults to 'cpu'.\n        dtype (torch.dtype, optional): Data type for the model. Defaults to torch.float64.\n        use_vae (bool, optional): If True, use a variational autoencoder. Defaults to False.\n        hidden_dim (int, optional): Hidden dimension for the encoder and decoder. Defaults to 128.\n        dropout (float, optional): Dropout rate. Defaults to 0.2.\n        verbose (bool, optional): If True, print training progress. Defaults to False.\n    \"\"\"\n    def __init__(self, \n                max_model_dim: int, \n                latent_dim: int,\n                device: str | torch.device = 'cpu',\n                dtype: torch.dtype = torch.float64,\n                use_vae: bool = False,\n                hidden_dim: int = 128,\n                dropout: float = 0.2,  \n                verbose: bool = False\n                ):\n\n        if use_vae:\n            logging.warning(\"Using a Variational Autoencoder. This is experimental and may not work as expected. We recommend using a deterministic autoencoder.\")\n\n        self.device = device\n        self.dtype = dtype\n        self.verbose = verbose\n        setup_logging(verbose)\n\n        self.encoder = MaskedEncoder(max_model_dim, latent_dim, use_vae=use_vae, hidden_dim=hidden_dim, dropout=dropout, device=device, dtype=dtype)\n        self.decoder = MaskedDecoder(latent_dim, max_model_dim, use_vae=use_vae, hidden_dim=hidden_dim, dropout=dropout, device=device, dtype=dtype)\n\n        self.max_model_dim = max_model_dim\n        self.loss_fn = use_vae\n        self.get_latent = use_vae\n\n        self.trained = False\n\n    @property\n    def loss_fn(self):\n        return self._loss_fn\n\n    @loss_fn.setter\n    def loss_fn(self, use_vae: bool = False):\n        if use_vae:\n            self._loss_fn = self.VAE_loss_fn\n        else:\n            self._loss_fn = self.reconstruction_loss_fn\n\n    @property\n    def get_latent(self):\n        return self._get_latent\n\n    @get_latent.setter\n    def get_latent(self, use_vae: bool = False):\n        if use_vae:\n            self._get_latent = self.get_z_vae\n        else:\n            self._get_latent = self.get_z_det\n\n    def VAE_loss_fn(self, \n                    input: torch.Tensor, \n                    reconstruction: torch.Tensor,\n                    input_mask: torch.Tensor, \n                    reconstructed_mask: torch.Tensor, \n                    mean: torch.Tensor, \n                    logvar: torch.Tensor\n                    ) -&gt; torch.Tensor:\n\n        # KL Divergence loss\n        loss = self.reconstruction_loss_fn(input, reconstruction, input_mask, reconstructed_mask)\n        kl_loss = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n\n        return loss + kl_loss\n\n    def reconstruction_loss_fn(self,\n                               input: torch.Tensor, \n                               reconstruction: torch.Tensor, \n                               input_mask: torch.Tensor, \n                               reconstructed_mask: torch.Tensor,\n                               ):\n        \"\"\"\n        Computes the combined reconstruction loss for values and mask.\n\n        Args:\n            input (torch.Tensor): Original input data of shape [N_samples, max_model_dim].\n            reconstruction (torch.Tensor): Reconstructed data of shape [N_samples, max_model_dim].\n            input_mask (torch.Tensor): Original NaN mask of shape [N_samples, max_model_dim].\n            reconstructed_mask (torch.Tensor): Reconstructed NaN mask.\n\n        Returns:\n            loss (torch.Tensor): Combined reconstruction loss.\n        \"\"\"\n        # Mask for valid entries\n        diff = torch.nan_to_num(input, nan=0.0) - torch.nan_to_num(reconstruction, nan=0.0)\n        #valid_loss = diff ** 2 MSE\n        valid_loss = torch.log(torch.cosh(diff)) # Huber loss\n        valid_loss = valid_loss.sum() / input_mask.sum()\n\n        # Binary cross-entropy for the NaN mask reconstruction\n        mask_loss = nn.functional.binary_cross_entropy(reconstructed_mask, input_mask)\n\n        #breakpoint()\n\n        return valid_loss + mask_loss\n\n\n    def train(self,\n            train_loader: DataLoader,\n            val_loader: DataLoader,\n            test_tensor: torch.Tensor=None,\n            start_epoch: int = 0,\n            epochs: int = 1000,\n            lr: float = 1e-3,\n            weight_decay: float = 0.0,\n            lambda_L1: float = 0.0,\n            early_stopping: bool | Callable = True,\n            stopping_kwargs: Optional[dict] = {},\n            path: str = './',\n            filename: str = 'autoencoder.pth',):\n\n        \"\"\"\n        Train the autoencoder model.\n\n        Args:\n            train_loader (DataLoader): DataLoader for training data.\n            val_loader (DataLoader): DataLoader for validation data.\n            test_tensor (torch.Tensor, optional): Test data for diagnostics. Defaults to None.\n            start_epoch (int, optional): The epoch to start training from. Defaults to 0.\n            epochs (int, optional): The number of epochs to train for. Defaults to 1000.\n            lr (float, optional): The learning rate for the optimizer. Defaults to 1e-3.\n            weight_decay (float, optional): L2 regularization strength. Defaults to 0.0.\n            lambda_L1 (float, optional): L1 regularization strength. Defaults to 0.0.\n            early_stopping (bool | Callable, optional): If True, use early stopping with default parameters.\n                If a callable is provided, it will be used as the early stopping function. Defaults to False.\n            stopping_kwargs (Optional[dict], optional): Additional arguments for the early stopping function. Defaults to {}.\n            path (str, optional): The directory path to save the model and diagnostics. Defaults to './'.\n            filename (str, optional): The filename to save the trained model. Defaults to 'autoencoder.pth'.\n        \"\"\"        \n\n        if test_tensor is not None:\n            self.test_tensor = test_tensor.to(self.device)\n            self.test_array = clean_chain(test_tensor.cpu().detach().numpy())\n        else:\n            self.test_tensor = None\n            self.test_array = None\n\n        epochs_losses = []\n        train_losses = []\n        val_losses = []\n\n        stopping_fn = None\n        converged = False\n        if isinstance(early_stopping, bool) and early_stopping:\n            stopping_fn = EarlyStopping(**stopping_kwargs)\n        elif isinstance(early_stopping, Callable):\n            stopping_fn = early_stopping\n        else:\n            logging.info(\"Early stopping disabled\")\n\n        trainedpath = path + filename\n        savepath = path + \"diagnostic/\"\n        os.makedirs(savepath, exist_ok=True)\n\n        logging.info(\"Training started\")\n        logging.info(f\"Saving diagnostics to {savepath}\")\n\n        if epochs &lt; start_epoch:\n            logging.info(\"Resuming training\")\n            epochs = start_epoch + epochs\n\n        optimizer = torch.optim.Adam(list(self.encoder.parameters()) + list(self.decoder.parameters()), lr=lr, weight_decay=weight_decay)\n\n        if val_loader:\n            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                                factor=0.5,\n                                                                patience=50,\n                                                                threshold=1e-5)\n        else:\n            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n\n        current_lr = lr\n\n        # use tqdm for progress bar only if verbose is True\n        epoch_iterator = tqdm(range(start_epoch, epochs), desc=\"Training\", disable=not self.verbose)\n\n        for epoch in epoch_iterator:\n\n            train_loss = self._train_one_epoch(train_loader=train_loader, optimizer=optimizer, lambda_L1=lambda_L1)\n            val_loss = self._validate_one_epoch(val_loader=val_loader, lambda_L1=lambda_L1) if val_loader else None\n\n            scheduler.step(val_loss) if val_loader else scheduler.step()\n\n            if stopping_fn:\n                if stopping_fn(val_loss):\n                    logging.info(f\"Early stopping at epoch {epoch}\")\n                    converged = True\n                    break\n\n            if epoch  &gt; 0 and epoch % 100 == 0:\n                if self.verbose:\n                    self._log_epoch(epoch, train_loss, val_loss, epochs_losses, train_losses, val_losses, savepath)\n                    if scheduler.get_last_lr()[0] != current_lr:\n                        current_lr = scheduler.get_last_lr()[0]\n                        logging.info(f\"New learning rate: {scheduler.get_last_lr()[0]}\")\n                    logging.info(\"Saving model @ epoch {}\".format(epoch))\n\n                self._save_model(trainedpath)\n\n        if stopping_fn and not converged:\n            logging.warning(\"Early stopping did not trigger\")\n\n        self.trained = True\n        self._save_model(trainedpath)\n\n    def reparameterize(self, \n                       mean: torch.Tensor, \n                       logvar: torch.Tensor\n                       ):\n        \"\"\"\n        Reparameterization trick for the VAE.\n\n        Args:\n            mean (torch.Tensor): Mean of the latent space.\n            logvar (torch.Tensor): Log-variance of the latent space.\n\n        Returns:\n            reparametrized (torch.Tensor): Reparameterized latent space.\n        \"\"\"\n\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mean + eps * std\n\n    def get_z_vae(self, x, mask):\n        \"\"\"\n        Get the latent representation of the input data using the VAE.\n\n        Args:\n            x (torch.Tensor): Input data of shape [N_samples, max_model_dim].\n            mask (torch.Tensor): Mask indicating valid dimensions (1 = valid, 0 = invalid).\n\n        Returns:\n            out (tuple[torch.Tensor, torch.Tensor, torch.Tensor]): Latent representation, mean, and log-variance.\n        \"\"\"\n\n        mean, logvar = self.encoder(x, mask)\n        z = self.reparameterize(mean, logvar)\n\n        return z, mean, logvar\n\n    def get_z_det(self, x, mask):\n        z = self.encoder(x, mask)\n        return z, None, None\n\n    def _train_one_epoch(self, \n                         train_loader: DataLoader, \n                         optimizer: torch.optim.Optimizer, \n                         lambda_L1: float\n                         ) -&gt; float:\n        \"\"\"\n        Perform a training step for one epoch.\n\n        Args:\n            train_loader (DataLoader): DataLoader for training data.\n            optimizer (torch.optim.Optimizer): The optimizer to use for training.\n            lambda_L1 (float): L1 regularization strength.\n\n        Returns:\n            float: The average training loss for the epoch.\n        \"\"\"\n\n        self.encoder.train()\n        self.decoder.train()\n        train_loss = 0\n\n        for batch in train_loader:\n            batch = batch[0].to(self.device, non_blocking=self.device.type == 'cuda')\n            mask = torch.isfinite(batch).to(self.dtype).to(self.device)\n\n            latent, mean, logvar = self.get_latent(batch, mask)\n\n            # Decode the latent representation\n            reconstructed_data, reconstructed_mask = self.decoder(latent)\n\n            # Reconstruction loss\n            loss = self.loss_fn(batch, reconstructed_data, mask, reconstructed_mask, mean, logvar)\n\n            #compute L1 regularization\n            L1_penalty = lambda_L1 * torch.norm(latent, p=1)\n\n            loss += L1_penalty\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        return train_loss / len(train_loader)\n\n    def _validate_one_epoch(self, \n                            val_loader: DataLoader, \n                            lambda_L1: float\n                            ):\n        \"\"\"\n        Perform a validation step for one epoch.\n\n        Args:\n            val_loader (DataLoader): DataLoader for validation data.\n            lambda_L1 (float): L1 regularization strength.\n\n        Returns:\n            float: The average validation loss for the epoch.\n        \"\"\"\n        self.encoder.eval()\n        self.decoder.eval()\n        val_loss = 0\n\n        with torch.no_grad():  # Disable gradient computation for validation\n            for batch in val_loader:\n                batch = batch[0].to(self.device, non_blocking=self.device.type == 'cuda')\n                mask = torch.isfinite(batch).to(self.dtype).to(self.device)\n\n                latent, mean, logvar = self.get_latent(batch, mask)\n\n                # Decode the latent representation\n                reconstructed_data, reconstructed_mask = self.decoder(latent)\n\n                # Reconstruction loss\n                loss = self.loss_fn(batch, reconstructed_data, mask, reconstructed_mask, mean, logvar)\n\n                #compute L1 regularization\n                L1_penalty = lambda_L1 * torch.norm(latent, p=1)\n                loss += L1_penalty\n\n                val_loss += loss.item()\n\n        return val_loss / len(val_loader)\n\n    def _log_epoch(self, \n                   epoch: int, \n                   train_loss: float, \n                   val_loss: float, \n                   epochs_losses: list, \n                   train_losses: list, \n                   val_losses: list, \n                   savepath: str, \n                   ndim: int = 15\n                   ):\n        \"\"\"\n        Logs the training and validation loss for a given epoch and updates the loss lists.\n\n        Args:\n            epoch (int): The current epoch number.\n            train_loss (float): The training loss for the current epoch.\n            val_loss (float or None): The validation loss for the current epoch, or None if not applicable.\n            epochs_losses (list): A list to store the epoch numbers.\n            train_losses (list): A list to store the training losses.\n            val_losses (list): A list to store the validation losses.\n            savepath (str): The directory path where the loss plot will be saved.\n            ndim (int, optional): The number of dimensions to plot in the corner plot. Defaults to 15.\n        \"\"\"\n\n        if val_loss is not None:\n            logging.info(f'Epoch {epoch}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n        else:\n            logging.info(f'Epoch {epoch}, Train Loss: {train_loss}')\n\n        epochs_losses.append(epoch)\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n\n        lossplot(epochs_losses, train_losses, val_losses, plot_dir=savepath, savename='autoencoder_loss')\n\n        if self.test_tensor is not None:\n            encoded = self.encode(self.test_tensor.reshape(-1, self.max_model_dim))\n            decoded = self.decode(encoded)\n            decoded_array = decoded.cpu().detach().numpy()\n            decoded_array = decoded_array.reshape(-1, self.test_array.shape[1])\n\n            logging.info('nans predicted by the autoencoder: %.i' % torch.isnan(decoded).sum().item())\n            logging.info('nans present in the target: %.i' % torch.isnan(self.test_tensor).sum().item())    \n\n            try:\n                decoded_array = clean_chain(decoded_array)\n                cornerplot_training(samples=decoded_array[:, :ndim], target_distribution=self.test_array[:, :ndim], epoch=epoch, plot_dir=savepath, savename='autoencoder_cornerplot')\n\n            except ValueError as e:\n                logging.info('Corner plot not generated: {} Resume training'.format(e))\n\n    def _save_model(self, path: str):\n        \"\"\"\n        Save the model to a file.\n\n        Args:\n            path (str): Path to save the model.\n        \"\"\"\n        torch.save({\n            'trained': self.trained,\n            'encoder': self.encoder.state_dict(),\n            'decoder': self.decoder.state_dict()\n        }, path)\n\n    def load_model(self, path: str):\n        \"\"\"\n        Load a saved model from a file.\n\n        Args:\n            path (str): Path to the saved model.\n        \"\"\"\n        checkpoint = torch.load(path)\n        self.encoder.load_state_dict(checkpoint['encoder'])\n        self.decoder.load_state_dict(checkpoint['decoder'])\n        self.trained = checkpoint['trained']\n\n    def encode(self, data: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Encode data into the latent space.\n\n        Args:\n            data (torch.Tensor): Input data of shape [N_samples, max_model_dim].\n\n        Returns:\n            torch.Tensor: Encoded data of shape [N_samples, latent_dim].\n        \"\"\"\n        mask = torch.isfinite(data).to(self.dtype).to(self.device)\n        self.encoder.eval()\n        with torch.no_grad():\n            latent, _, _ = self.get_latent(data, mask)\n            return latent\n\n    def decode(self, latent: torch.Tensor, threshold: float = 0.5) -&gt; torch.Tensor:\n        \"\"\"\n        Decode data from the latent space.\n\n        Args:\n            latent (torch.Tensor): Input latent representation of shape [N_samples, latent_dim].\n            threshold (float): Threshold to classify mask probabilities as valid or NaN.\n\n        Returns:\n            torch.Tensor: Decoded data of shape [N_samples, max_model_dim].\n        \"\"\"\n\n        self.decoder.eval()\n        with torch.no_grad():\n            reconstructed_data, reconstructed_mask =  self.decoder(latent)\n\n        return self.postprocess_decoder_output(reconstructed_data, reconstructed_mask, threshold)\n\n    def postprocess_decoder_output(self, reconstructed_data, reconstructed_mask, threshold=0.5):\n        \"\"\"\n        Post-process the decoder output to reintroduce NaNs where necessary.\n\n        Args:\n            reconstructed_data (torch.Tensor): Reconstructed data of shape [N_samples, max_model_dim].\n            reconstructed_mask (torch.Tensor): Reconstructed NaN mask.\n            threshold (float): Threshold to classify mask probabilities as valid or NaN.\n\n        Returns:\n            reconstructed_data (torch.Tensor): Post-processed data with NaNs reintroduced.\n        \"\"\"\n        nan_positions = (reconstructed_mask &lt; threshold)\n        reconstructed_data[nan_positions] = float('nan')  # Replace positions with NaN\n        return reconstructed_data\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedAutoEncoder.decode","title":"<code>decode(latent, threshold=0.5)</code>","text":"<p>Decode data from the latent space.</p> <p>Parameters:</p> Name Type Description Default <code>latent</code> <code>Tensor</code> <p>Input latent representation of shape [N_samples, latent_dim].</p> required <code>threshold</code> <code>float</code> <p>Threshold to classify mask probabilities as valid or NaN.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Decoded data of shape [N_samples, max_model_dim].</p> Source code in <code>flowevidence/encode.py</code> <pre><code>def decode(self, latent: torch.Tensor, threshold: float = 0.5) -&gt; torch.Tensor:\n    \"\"\"\n    Decode data from the latent space.\n\n    Args:\n        latent (torch.Tensor): Input latent representation of shape [N_samples, latent_dim].\n        threshold (float): Threshold to classify mask probabilities as valid or NaN.\n\n    Returns:\n        torch.Tensor: Decoded data of shape [N_samples, max_model_dim].\n    \"\"\"\n\n    self.decoder.eval()\n    with torch.no_grad():\n        reconstructed_data, reconstructed_mask =  self.decoder(latent)\n\n    return self.postprocess_decoder_output(reconstructed_data, reconstructed_mask, threshold)\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedAutoEncoder.encode","title":"<code>encode(data)</code>","text":"<p>Encode data into the latent space.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Tensor</code> <p>Input data of shape [N_samples, max_model_dim].</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Encoded data of shape [N_samples, latent_dim].</p> Source code in <code>flowevidence/encode.py</code> <pre><code>def encode(self, data: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Encode data into the latent space.\n\n    Args:\n        data (torch.Tensor): Input data of shape [N_samples, max_model_dim].\n\n    Returns:\n        torch.Tensor: Encoded data of shape [N_samples, latent_dim].\n    \"\"\"\n    mask = torch.isfinite(data).to(self.dtype).to(self.device)\n    self.encoder.eval()\n    with torch.no_grad():\n        latent, _, _ = self.get_latent(data, mask)\n        return latent\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedAutoEncoder.get_z_vae","title":"<code>get_z_vae(x, mask)</code>","text":"<p>Get the latent representation of the input data using the VAE.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data of shape [N_samples, max_model_dim].</p> required <code>mask</code> <code>Tensor</code> <p>Mask indicating valid dimensions (1 = valid, 0 = invalid).</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>tuple[Tensor, Tensor, Tensor]</code> <p>Latent representation, mean, and log-variance.</p> Source code in <code>flowevidence/encode.py</code> <pre><code>def get_z_vae(self, x, mask):\n    \"\"\"\n    Get the latent representation of the input data using the VAE.\n\n    Args:\n        x (torch.Tensor): Input data of shape [N_samples, max_model_dim].\n        mask (torch.Tensor): Mask indicating valid dimensions (1 = valid, 0 = invalid).\n\n    Returns:\n        out (tuple[torch.Tensor, torch.Tensor, torch.Tensor]): Latent representation, mean, and log-variance.\n    \"\"\"\n\n    mean, logvar = self.encoder(x, mask)\n    z = self.reparameterize(mean, logvar)\n\n    return z, mean, logvar\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedAutoEncoder.load_model","title":"<code>load_model(path)</code>","text":"<p>Load a saved model from a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the saved model.</p> required Source code in <code>flowevidence/encode.py</code> <pre><code>def load_model(self, path: str):\n    \"\"\"\n    Load a saved model from a file.\n\n    Args:\n        path (str): Path to the saved model.\n    \"\"\"\n    checkpoint = torch.load(path)\n    self.encoder.load_state_dict(checkpoint['encoder'])\n    self.decoder.load_state_dict(checkpoint['decoder'])\n    self.trained = checkpoint['trained']\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedAutoEncoder.postprocess_decoder_output","title":"<code>postprocess_decoder_output(reconstructed_data, reconstructed_mask, threshold=0.5)</code>","text":"<p>Post-process the decoder output to reintroduce NaNs where necessary.</p> <p>Parameters:</p> Name Type Description Default <code>reconstructed_data</code> <code>Tensor</code> <p>Reconstructed data of shape [N_samples, max_model_dim].</p> required <code>reconstructed_mask</code> <code>Tensor</code> <p>Reconstructed NaN mask.</p> required <code>threshold</code> <code>float</code> <p>Threshold to classify mask probabilities as valid or NaN.</p> <code>0.5</code> <p>Returns:</p> Name Type Description <code>reconstructed_data</code> <code>Tensor</code> <p>Post-processed data with NaNs reintroduced.</p> Source code in <code>flowevidence/encode.py</code> <pre><code>def postprocess_decoder_output(self, reconstructed_data, reconstructed_mask, threshold=0.5):\n    \"\"\"\n    Post-process the decoder output to reintroduce NaNs where necessary.\n\n    Args:\n        reconstructed_data (torch.Tensor): Reconstructed data of shape [N_samples, max_model_dim].\n        reconstructed_mask (torch.Tensor): Reconstructed NaN mask.\n        threshold (float): Threshold to classify mask probabilities as valid or NaN.\n\n    Returns:\n        reconstructed_data (torch.Tensor): Post-processed data with NaNs reintroduced.\n    \"\"\"\n    nan_positions = (reconstructed_mask &lt; threshold)\n    reconstructed_data[nan_positions] = float('nan')  # Replace positions with NaN\n    return reconstructed_data\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedAutoEncoder.reconstruction_loss_fn","title":"<code>reconstruction_loss_fn(input, reconstruction, input_mask, reconstructed_mask)</code>","text":"<p>Computes the combined reconstruction loss for values and mask.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Tensor</code> <p>Original input data of shape [N_samples, max_model_dim].</p> required <code>reconstruction</code> <code>Tensor</code> <p>Reconstructed data of shape [N_samples, max_model_dim].</p> required <code>input_mask</code> <code>Tensor</code> <p>Original NaN mask of shape [N_samples, max_model_dim].</p> required <code>reconstructed_mask</code> <code>Tensor</code> <p>Reconstructed NaN mask.</p> required <p>Returns:</p> Name Type Description <code>loss</code> <code>Tensor</code> <p>Combined reconstruction loss.</p> Source code in <code>flowevidence/encode.py</code> <pre><code>def reconstruction_loss_fn(self,\n                           input: torch.Tensor, \n                           reconstruction: torch.Tensor, \n                           input_mask: torch.Tensor, \n                           reconstructed_mask: torch.Tensor,\n                           ):\n    \"\"\"\n    Computes the combined reconstruction loss for values and mask.\n\n    Args:\n        input (torch.Tensor): Original input data of shape [N_samples, max_model_dim].\n        reconstruction (torch.Tensor): Reconstructed data of shape [N_samples, max_model_dim].\n        input_mask (torch.Tensor): Original NaN mask of shape [N_samples, max_model_dim].\n        reconstructed_mask (torch.Tensor): Reconstructed NaN mask.\n\n    Returns:\n        loss (torch.Tensor): Combined reconstruction loss.\n    \"\"\"\n    # Mask for valid entries\n    diff = torch.nan_to_num(input, nan=0.0) - torch.nan_to_num(reconstruction, nan=0.0)\n    #valid_loss = diff ** 2 MSE\n    valid_loss = torch.log(torch.cosh(diff)) # Huber loss\n    valid_loss = valid_loss.sum() / input_mask.sum()\n\n    # Binary cross-entropy for the NaN mask reconstruction\n    mask_loss = nn.functional.binary_cross_entropy(reconstructed_mask, input_mask)\n\n    #breakpoint()\n\n    return valid_loss + mask_loss\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedAutoEncoder.reparameterize","title":"<code>reparameterize(mean, logvar)</code>","text":"<p>Reparameterization trick for the VAE.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>Tensor</code> <p>Mean of the latent space.</p> required <code>logvar</code> <code>Tensor</code> <p>Log-variance of the latent space.</p> required <p>Returns:</p> Name Type Description <code>reparametrized</code> <code>Tensor</code> <p>Reparameterized latent space.</p> Source code in <code>flowevidence/encode.py</code> <pre><code>def reparameterize(self, \n                   mean: torch.Tensor, \n                   logvar: torch.Tensor\n                   ):\n    \"\"\"\n    Reparameterization trick for the VAE.\n\n    Args:\n        mean (torch.Tensor): Mean of the latent space.\n        logvar (torch.Tensor): Log-variance of the latent space.\n\n    Returns:\n        reparametrized (torch.Tensor): Reparameterized latent space.\n    \"\"\"\n\n    std = torch.exp(0.5 * logvar)\n    eps = torch.randn_like(std)\n    return mean + eps * std\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedAutoEncoder.train","title":"<code>train(train_loader, val_loader, test_tensor=None, start_epoch=0, epochs=1000, lr=0.001, weight_decay=0.0, lambda_L1=0.0, early_stopping=True, stopping_kwargs={}, path='./', filename='autoencoder.pth')</code>","text":"<p>Train the autoencoder model.</p> <p>Parameters:</p> Name Type Description Default <code>train_loader</code> <code>DataLoader</code> <p>DataLoader for training data.</p> required <code>val_loader</code> <code>DataLoader</code> <p>DataLoader for validation data.</p> required <code>test_tensor</code> <code>Tensor</code> <p>Test data for diagnostics. Defaults to None.</p> <code>None</code> <code>start_epoch</code> <code>int</code> <p>The epoch to start training from. Defaults to 0.</p> <code>0</code> <code>epochs</code> <code>int</code> <p>The number of epochs to train for. Defaults to 1000.</p> <code>1000</code> <code>lr</code> <code>float</code> <p>The learning rate for the optimizer. Defaults to 1e-3.</p> <code>0.001</code> <code>weight_decay</code> <code>float</code> <p>L2 regularization strength. Defaults to 0.0.</p> <code>0.0</code> <code>lambda_L1</code> <code>float</code> <p>L1 regularization strength. Defaults to 0.0.</p> <code>0.0</code> <code>early_stopping</code> <code>bool | Callable</code> <p>If True, use early stopping with default parameters. If a callable is provided, it will be used as the early stopping function. Defaults to False.</p> <code>True</code> <code>stopping_kwargs</code> <code>Optional[dict]</code> <p>Additional arguments for the early stopping function. Defaults to {}.</p> <code>{}</code> <code>path</code> <code>str</code> <p>The directory path to save the model and diagnostics. Defaults to './'.</p> <code>'./'</code> <code>filename</code> <code>str</code> <p>The filename to save the trained model. Defaults to 'autoencoder.pth'.</p> <code>'autoencoder.pth'</code> Source code in <code>flowevidence/encode.py</code> <pre><code>def train(self,\n        train_loader: DataLoader,\n        val_loader: DataLoader,\n        test_tensor: torch.Tensor=None,\n        start_epoch: int = 0,\n        epochs: int = 1000,\n        lr: float = 1e-3,\n        weight_decay: float = 0.0,\n        lambda_L1: float = 0.0,\n        early_stopping: bool | Callable = True,\n        stopping_kwargs: Optional[dict] = {},\n        path: str = './',\n        filename: str = 'autoencoder.pth',):\n\n    \"\"\"\n    Train the autoencoder model.\n\n    Args:\n        train_loader (DataLoader): DataLoader for training data.\n        val_loader (DataLoader): DataLoader for validation data.\n        test_tensor (torch.Tensor, optional): Test data for diagnostics. Defaults to None.\n        start_epoch (int, optional): The epoch to start training from. Defaults to 0.\n        epochs (int, optional): The number of epochs to train for. Defaults to 1000.\n        lr (float, optional): The learning rate for the optimizer. Defaults to 1e-3.\n        weight_decay (float, optional): L2 regularization strength. Defaults to 0.0.\n        lambda_L1 (float, optional): L1 regularization strength. Defaults to 0.0.\n        early_stopping (bool | Callable, optional): If True, use early stopping with default parameters.\n            If a callable is provided, it will be used as the early stopping function. Defaults to False.\n        stopping_kwargs (Optional[dict], optional): Additional arguments for the early stopping function. Defaults to {}.\n        path (str, optional): The directory path to save the model and diagnostics. Defaults to './'.\n        filename (str, optional): The filename to save the trained model. Defaults to 'autoencoder.pth'.\n    \"\"\"        \n\n    if test_tensor is not None:\n        self.test_tensor = test_tensor.to(self.device)\n        self.test_array = clean_chain(test_tensor.cpu().detach().numpy())\n    else:\n        self.test_tensor = None\n        self.test_array = None\n\n    epochs_losses = []\n    train_losses = []\n    val_losses = []\n\n    stopping_fn = None\n    converged = False\n    if isinstance(early_stopping, bool) and early_stopping:\n        stopping_fn = EarlyStopping(**stopping_kwargs)\n    elif isinstance(early_stopping, Callable):\n        stopping_fn = early_stopping\n    else:\n        logging.info(\"Early stopping disabled\")\n\n    trainedpath = path + filename\n    savepath = path + \"diagnostic/\"\n    os.makedirs(savepath, exist_ok=True)\n\n    logging.info(\"Training started\")\n    logging.info(f\"Saving diagnostics to {savepath}\")\n\n    if epochs &lt; start_epoch:\n        logging.info(\"Resuming training\")\n        epochs = start_epoch + epochs\n\n    optimizer = torch.optim.Adam(list(self.encoder.parameters()) + list(self.decoder.parameters()), lr=lr, weight_decay=weight_decay)\n\n    if val_loader:\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                            factor=0.5,\n                                                            patience=50,\n                                                            threshold=1e-5)\n    else:\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n\n    current_lr = lr\n\n    # use tqdm for progress bar only if verbose is True\n    epoch_iterator = tqdm(range(start_epoch, epochs), desc=\"Training\", disable=not self.verbose)\n\n    for epoch in epoch_iterator:\n\n        train_loss = self._train_one_epoch(train_loader=train_loader, optimizer=optimizer, lambda_L1=lambda_L1)\n        val_loss = self._validate_one_epoch(val_loader=val_loader, lambda_L1=lambda_L1) if val_loader else None\n\n        scheduler.step(val_loss) if val_loader else scheduler.step()\n\n        if stopping_fn:\n            if stopping_fn(val_loss):\n                logging.info(f\"Early stopping at epoch {epoch}\")\n                converged = True\n                break\n\n        if epoch  &gt; 0 and epoch % 100 == 0:\n            if self.verbose:\n                self._log_epoch(epoch, train_loss, val_loss, epochs_losses, train_losses, val_losses, savepath)\n                if scheduler.get_last_lr()[0] != current_lr:\n                    current_lr = scheduler.get_last_lr()[0]\n                    logging.info(f\"New learning rate: {scheduler.get_last_lr()[0]}\")\n                logging.info(\"Saving model @ epoch {}\".format(epoch))\n\n            self._save_model(trainedpath)\n\n    if stopping_fn and not converged:\n        logging.warning(\"Early stopping did not trigger\")\n\n    self.trained = True\n    self._save_model(trainedpath)\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedDecoder","title":"<code>MaskedDecoder</code>","text":"<p>               Bases: <code>Module</code></p> <p>Decoder for reconstructing data from the latent space.</p> <p>Parameters:</p> Name Type Description Default <code>latent_dim</code> <code>int</code> <p>Dimensionality of the latent space.</p> required <code>max_model_dim</code> <code>int</code> <p>Maximum dimensionality of the output (original data space).</p> required <code>hidden_dim</code> <code>int</code> <p>Hidden dimension for the decoder. Defaults to 128.</p> <code>128</code> <code>dropout</code> <code>float</code> <p>Dropout rate. Defaults to 0.2.</p> <code>0.2</code> <code>use_vae</code> <code>bool</code> <p>If True, use a variational autoencoder. Defaults to False.</p> <code>False</code> <code>device</code> <code>str | device</code> <p>Device to use for training. Defaults to 'cpu'.</p> <code>'cpu'</code> <code>dtype</code> <code>dtype</code> <p>Data type for the model. Defaults to torch.float64.</p> <code>float64</code> Source code in <code>flowevidence/encode.py</code> <pre><code>class MaskedDecoder(nn.Module):\n    \"\"\"\n    Decoder for reconstructing data from the latent space.\n\n    Args:\n        latent_dim (int): Dimensionality of the latent space.\n        max_model_dim (int): Maximum dimensionality of the output (original data space).\n        hidden_dim (int, optional): Hidden dimension for the decoder. Defaults to 128.\n        dropout (float, optional): Dropout rate. Defaults to 0.2.\n        use_vae (bool, optional): If True, use a variational autoencoder. Defaults to False.\n        device (str | torch.device, optional): Device to use for training. Defaults to 'cpu'.\n        dtype (torch.dtype, optional): Data type for the model. Defaults to torch.float64.\n    \"\"\"\n    def __init__(self, \n                 latent_dim: int, \n                 max_model_dim: int,\n                 hidden_dim: int = 128,\n                 dropout: float = 0.2,\n                 use_vae: bool = False,\n                 device: str | torch.device = 'cpu',\n                 dtype: torch.dtype = torch.float64\n                 ):\n\n        super().__init__()\n        self.latent_dim = latent_dim\n        self.max_model_dim = max_model_dim\n\n        self.fc1 = nn.Linear(latent_dim, hidden_dim, device=device, dtype=dtype)\n        self.bn1 = nn.BatchNorm1d(hidden_dim, device=device, dtype=dtype)\n\n        self.fc2 = nn.Linear(hidden_dim, 2*hidden_dim, device=device, dtype=dtype)\n        self.bn2 = nn.BatchNorm1d(2*hidden_dim, device=device, dtype=dtype)\n\n        self.fc3 = nn.Linear(2*hidden_dim, 4*hidden_dim, device=device, dtype=dtype)\n        self.bn3 = nn.BatchNorm1d(4*hidden_dim, device=device, dtype=dtype)\n\n        self.fc4 = nn.Linear(4*hidden_dim, 2*hidden_dim, device=device, dtype=dtype)\n        self.bn4 = nn.BatchNorm1d(2*hidden_dim, device=device, dtype=dtype)\n\n        self.fc5 = nn.Linear(2*hidden_dim, 2*max_model_dim, device=device, dtype=dtype)\n\n        if use_vae:\n            self.out = torch.tanh\n        else:\n            self.out = lambda x: x\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=dropout) # Dropout layer\n\n    def forward(self, \n                z: torch.Tensor\n                ) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the decoder.\n\n        Args:\n            z (torch.Tensor): Input latent representation (batch_size, latent_dim).\n\n        Returns:\n            torch.Tensor: Reconstructed data (batch_size, max_model_dim).\n        \"\"\"\n        #return self.decoder(z)\n        x = self.fc1(z)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n\n        x = self.fc2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        #x = self.dropout(x)\n\n        x = self.fc3(x)\n        x = self.bn3(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n\n        x = self.fc4(x)\n        x = self.bn4(x)\n        x = self.relu(x)\n        #x = self.dropout(x)\n\n        x = self.fc5(x)\n        #x = self.out(x)\n\n        reconstructed_data = x[:, :x.shape[1]//2]  # First half of the output is the reconstructed data\n        reconstructed_mask = torch.sigmoid(x[:, x.shape[1]//2:])  # Use sigmoid for mask probabilities\n        return reconstructed_data, reconstructed_mask\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedDecoder.forward","title":"<code>forward(z)</code>","text":"<p>Forward pass of the decoder.</p> <p>Parameters:</p> Name Type Description Default <code>z</code> <code>Tensor</code> <p>Input latent representation (batch_size, latent_dim).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Reconstructed data (batch_size, max_model_dim).</p> Source code in <code>flowevidence/encode.py</code> <pre><code>def forward(self, \n            z: torch.Tensor\n            ) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass of the decoder.\n\n    Args:\n        z (torch.Tensor): Input latent representation (batch_size, latent_dim).\n\n    Returns:\n        torch.Tensor: Reconstructed data (batch_size, max_model_dim).\n    \"\"\"\n    #return self.decoder(z)\n    x = self.fc1(z)\n    x = self.bn1(x)\n    x = self.relu(x)\n    x = self.dropout(x)\n\n    x = self.fc2(x)\n    x = self.bn2(x)\n    x = self.relu(x)\n    #x = self.dropout(x)\n\n    x = self.fc3(x)\n    x = self.bn3(x)\n    x = self.relu(x)\n    x = self.dropout(x)\n\n    x = self.fc4(x)\n    x = self.bn4(x)\n    x = self.relu(x)\n    #x = self.dropout(x)\n\n    x = self.fc5(x)\n    #x = self.out(x)\n\n    reconstructed_data = x[:, :x.shape[1]//2]  # First half of the output is the reconstructed data\n    reconstructed_mask = torch.sigmoid(x[:, x.shape[1]//2:])  # Use sigmoid for mask probabilities\n    return reconstructed_data, reconstructed_mask\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedEncoder","title":"<code>MaskedEncoder</code>","text":"<p>               Bases: <code>Module</code></p> <p>Encoder to handle variable-dimension data (e.g., RJ-MCMC branches).</p> <p>Parameters:</p> Name Type Description Default <code>max_model_dim</code> <code>int</code> <p>Maximum dimensionality of the input data.</p> required <code>latent_dim</code> <code>int</code> <p>Dimensionality of the latent space.</p> required <code>hidden_dim</code> <code>int</code> <p>Hidden dimension for the encoder. Defaults to 128.</p> <code>128</code> <code>dropout</code> <code>float</code> <p>Dropout rate. Defaults to 0.2.</p> <code>0.2</code> <code>use_vae</code> <code>bool</code> <p>If True, use a variational autoencoder. Defaults to False.</p> <code>False</code> <code>device</code> <code>str | device</code> <p>Device to use for training. Defaults to 'cpu'.</p> <code>'cpu'</code> <code>dtype</code> <code>dtype</code> <p>Data type for the model. Defaults to torch.float64.</p> <code>float64</code> Source code in <code>flowevidence/encode.py</code> <pre><code>class MaskedEncoder(nn.Module):\n    \"\"\"\n    Encoder to handle variable-dimension data (e.g., RJ-MCMC branches).\n\n    Args:\n        max_model_dim (int): Maximum dimensionality of the input data.\n        latent_dim (int): Dimensionality of the latent space.\n        hidden_dim (int, optional): Hidden dimension for the encoder. Defaults to 128.\n        dropout (float, optional): Dropout rate. Defaults to 0.2.\n        use_vae (bool, optional): If True, use a variational autoencoder. Defaults to False.\n        device (str | torch.device, optional): Device to use for training. Defaults to 'cpu'.\n        dtype (torch.dtype, optional): Data type for the model. Defaults to torch.float64.\n    \"\"\"\n    def __init__(self, \n                 max_model_dim: int, \n                 latent_dim: int,\n                 hidden_dim: int = 128,\n                 dropout: float = 0.2,\n                 use_vae: bool = False,\n                 device: str | torch.device = 'cpu',\n                 dtype: torch.dtype = torch.float64\n                 ):\n\n        super().__init__()\n\n        self.fc1 = nn.Linear(2*max_model_dim, hidden_dim, device=device, dtype=dtype)\n        self.bn1 = nn.BatchNorm1d(hidden_dim, device=device, dtype=dtype) \n\n        self.fc2 = nn.Linear(hidden_dim, 2*hidden_dim, device=device, dtype=dtype)\n        self.bn2 = nn.BatchNorm1d(2*hidden_dim, device=device, dtype=dtype)\n\n        self.fc3 = nn.Linear(2*hidden_dim, 4*hidden_dim, device=device, dtype=dtype)\n        self.bn3 = nn.BatchNorm1d(4*hidden_dim, device=device, dtype=dtype)\n\n        self.fc4 = nn.Linear(4*hidden_dim, 2*hidden_dim, device=device, dtype=dtype)\n        self.bn4 = nn.BatchNorm1d(2*hidden_dim, device=device, dtype=dtype)\n\n        if use_vae:\n            self.fc5_mu = nn.Linear(2*hidden_dim, latent_dim, device=device, dtype=dtype)\n            self.fc5_logvar = nn.Linear(2*hidden_dim, latent_dim, device=device, dtype=dtype)\n        else:\n            self.fc5 = nn.Linear(2*hidden_dim, latent_dim, device=device, dtype=dtype)\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=dropout)  # Dropout layer\n\n        self.forward = self.forward_vae if use_vae else self.forward_det\n\n    def forward_det(self, \n                    x: torch.Tensor, \n                    mask: torch.Tensor\n                    ) -&gt; torch.Tensor:\n        \"\"\"\n        Encodes input data into a latent space, considering the mask for valid data.\n\n        Args:\n            x (torch.Tensor): Input data of shape [N_samples, max_model_dim].\n            mask (torch.Tensor): Mask indicating valid dimensions (1 = valid, 0 = invalid).\n\n        Returns:\n            torch.Tensor: Encoded data of shape [N_samples, latent_dim].\n        \"\"\"\n        combined = torch.cat((x.nan_to_num(0.0), mask), dim=1)  # Replace NaNs in x with 0 and concatenate with mask\n        z = self.fc1(combined)\n        z = self.bn1(z)\n        z = self.relu(z)\n        z = self.dropout(z)\n\n        z = self.fc2(z)\n        z = self.bn2(z)\n        z = self.relu(z)\n        #z = self.dropout(z)\n\n        z = self.fc3(z)\n        z = self.bn3(z)\n        z = self.relu(z)\n        z = self.dropout(z)\n\n        z = self.fc4(z)\n        z = self.bn4(z)\n        z = self.relu(z)\n        #z = self.dropout(z)\n\n        z = self.fc5(z)\n        return z\n\n    def forward_vae(self, \n                    x: torch.Tensor, \n                    mask: torch.Tensor\n                    ) -&gt; tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Encodes input data into a latent space, considering the mask for valid data. \n\n        Args:\n            x (torch.Tensor): Input data of shape [N_samples, max_model_dim].\n            mask (torch.Tensor): Mask indicating valid dimensions (1 = valid, 0 = invalid).\n\n        Returns:\n            tuple[torch.Tensor, torch.Tensor]: Encoded data mean and log-variance of the latent space.\n        \"\"\"\n\n        combined = torch.cat((x.nan_to_num(0.0), mask), dim=1)\n        z = self.fc1(combined)\n        z = self.bn1(z)\n        z = self.relu(z)\n        z = self.dropout(z)\n\n        z = self.fc2(z)\n        z = self.bn2(z)\n        z = self.relu(z)\n        #z = self.dropout(z)\n\n        z = self.fc3(z)\n        z = self.bn3(z)\n        z = self.relu(z)\n        z = self.dropout(z)\n\n        z = self.fc4(z)\n        z = self.bn4(z)\n        z = self.relu(z)\n        #z = self.dropout(z)\n\n        mu = self.fc5_mu(z)\n        logvar = self.fc5_logvar(z)\n\n        return mu, logvar\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedEncoder.forward_det","title":"<code>forward_det(x, mask)</code>","text":"<p>Encodes input data into a latent space, considering the mask for valid data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data of shape [N_samples, max_model_dim].</p> required <code>mask</code> <code>Tensor</code> <p>Mask indicating valid dimensions (1 = valid, 0 = invalid).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Encoded data of shape [N_samples, latent_dim].</p> Source code in <code>flowevidence/encode.py</code> <pre><code>def forward_det(self, \n                x: torch.Tensor, \n                mask: torch.Tensor\n                ) -&gt; torch.Tensor:\n    \"\"\"\n    Encodes input data into a latent space, considering the mask for valid data.\n\n    Args:\n        x (torch.Tensor): Input data of shape [N_samples, max_model_dim].\n        mask (torch.Tensor): Mask indicating valid dimensions (1 = valid, 0 = invalid).\n\n    Returns:\n        torch.Tensor: Encoded data of shape [N_samples, latent_dim].\n    \"\"\"\n    combined = torch.cat((x.nan_to_num(0.0), mask), dim=1)  # Replace NaNs in x with 0 and concatenate with mask\n    z = self.fc1(combined)\n    z = self.bn1(z)\n    z = self.relu(z)\n    z = self.dropout(z)\n\n    z = self.fc2(z)\n    z = self.bn2(z)\n    z = self.relu(z)\n    #z = self.dropout(z)\n\n    z = self.fc3(z)\n    z = self.bn3(z)\n    z = self.relu(z)\n    z = self.dropout(z)\n\n    z = self.fc4(z)\n    z = self.bn4(z)\n    z = self.relu(z)\n    #z = self.dropout(z)\n\n    z = self.fc5(z)\n    return z\n</code></pre>"},{"location":"api/encode/#flowevidence.encode.MaskedEncoder.forward_vae","title":"<code>forward_vae(x, mask)</code>","text":"<p>Encodes input data into a latent space, considering the mask for valid data. </p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data of shape [N_samples, max_model_dim].</p> required <code>mask</code> <code>Tensor</code> <p>Mask indicating valid dimensions (1 = valid, 0 = invalid).</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>tuple[torch.Tensor, torch.Tensor]: Encoded data mean and log-variance of the latent space.</p> Source code in <code>flowevidence/encode.py</code> <pre><code>def forward_vae(self, \n                x: torch.Tensor, \n                mask: torch.Tensor\n                ) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Encodes input data into a latent space, considering the mask for valid data. \n\n    Args:\n        x (torch.Tensor): Input data of shape [N_samples, max_model_dim].\n        mask (torch.Tensor): Mask indicating valid dimensions (1 = valid, 0 = invalid).\n\n    Returns:\n        tuple[torch.Tensor, torch.Tensor]: Encoded data mean and log-variance of the latent space.\n    \"\"\"\n\n    combined = torch.cat((x.nan_to_num(0.0), mask), dim=1)\n    z = self.fc1(combined)\n    z = self.bn1(z)\n    z = self.relu(z)\n    z = self.dropout(z)\n\n    z = self.fc2(z)\n    z = self.bn2(z)\n    z = self.relu(z)\n    #z = self.dropout(z)\n\n    z = self.fc3(z)\n    z = self.bn3(z)\n    z = self.relu(z)\n    z = self.dropout(z)\n\n    z = self.fc4(z)\n    z = self.bn4(z)\n    z = self.relu(z)\n    #z = self.dropout(z)\n\n    mu = self.fc5_mu(z)\n    logvar = self.fc5_logvar(z)\n\n    return mu, logvar\n</code></pre>"},{"location":"api/transforms/","title":"API Documentation: Transforms","text":""},{"location":"api/transforms/#implemented-transformations-and-default-options","title":"Implemented transformations and default options.","text":""},{"location":"api/transforms/#flowevidence.transforms.get_flow_builder","title":"<code>get_flow_builder(model)</code>","text":"<p>Returns the transformation class based on the specified model type.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model type.</p> required <p>Returns:</p> Name Type Description <code>get_transform</code> <code>function</code> <p>The transformation class to use.</p> Source code in <code>flowevidence/transforms.py</code> <pre><code>def get_flow_builder(model):\n    \"\"\"\n    Returns the transformation class based on the specified model type.\n\n    Args:\n        model (str): The model type.\n\n    Returns:\n        get_transform (function): The transformation class to use.\n    \"\"\"\n\n    transform_classes = {\n        'maf': get_maf_transform,\n        'nvp': get_nvp_transform,\n        'rqs': get_rqs_transform\n    }\n\n    return transform_classes[model]\n</code></pre>"},{"location":"api/transforms/#flowevidence.transforms.get_tranform_kwargs","title":"<code>get_tranform_kwargs(model)</code>","text":"<p>Returns the default keyword arguments for the specified model type.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model type.</p> required <p>Returns:</p> Name Type Description <code>kwargs</code> <code>dict</code> <p>The default keyword arguments for the model type.</p> Source code in <code>flowevidence/transforms.py</code> <pre><code>def get_tranform_kwargs(model: str):\n    \"\"\"\n    Returns the default keyword arguments for the specified model type.\n\n    Args:\n        model (str): The model type.\n\n    Returns:\n        kwargs (dict): The default keyword arguments for the model type.\n    \"\"\"\n\n    maf_dict = {\n        'hidden_features': 128,\n        'activation': nn.ReLU(),\n        'use_batch_norm': True,\n        'dropout_probability': 0.1,\n    }\n\n    nvp_dict = {\n        'layers': None,\n        'leaky': 0.0,\n        'init_zeros': True,\n        'hidden_multiplier': 2,\n        'dropout': 0.0,\n    }\n\n    rqs_dict = {\n        'num_blocks': 5,\n        'num_hidden_channels': 128,\n        'num_bins': 8,\n        'dropout_probability': 0.1,\n    }\n\n    kwargs = {\n        'maf': maf_dict,\n        'nvp': nvp_dict,\n        'rqs': rqs_dict\n    }\n\n    return kwargs[model]\n</code></pre>"},{"location":"api/transforms/#flowevidence.transforms.get_flow_transforms","title":"<code>get_flow_transforms(num_dims, num_flow_steps, model='maf', extra_kwargs={})</code>","text":"<p>Returns the transformation class and its default keyword arguments based on the specified model type.</p> <p>Parameters:</p> Name Type Description Default <code>num_dims</code> <code>int</code> <p>The number of dimensions in the input.</p> required <code>num_flow_steps</code> <code>int</code> <p>The number of flow steps in the transformation.</p> required <code>model</code> <code>str</code> <p>The model type.</p> <code>'maf'</code> <code>extra_kwargs</code> <code>dict</code> <p>Additional keyword arguments for the transformation.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>transform_class</code> <code>Transform</code> <p>The transformation class to use.</p> <code>default_kwargs</code> <code>dict</code> <p>The default keyword arguments for the transformation class.</p> Source code in <code>flowevidence/transforms.py</code> <pre><code>def get_flow_transforms(num_dims: int, \n                        num_flow_steps: int, \n                        model: str = 'maf', \n                        extra_kwargs: dict = {}):\n    \"\"\"\n    Returns the transformation class and its default keyword arguments based on the specified model type.\n\n    Args:\n        num_dims (int): The number of dimensions in the input.\n        num_flow_steps (int): The number of flow steps in the transformation.\n        model (str): The model type.\n        extra_kwargs (dict): Additional keyword arguments for the transformation.\n\n    Returns:\n        transform_class (Transform): The transformation class to use.\n        default_kwargs (dict): The default keyword arguments for the transformation class.    \n    \"\"\"\n\n    default_kwargs = get_tranform_kwargs(model).copy()\n    default_kwargs.update(extra_kwargs) \n\n    build_flow = get_flow_builder(model)\n\n    flows = build_flow(num_flow_steps, num_dims, **default_kwargs)\n\n    return flows\n</code></pre>"},{"location":"api/utils/","title":"API Documentation: Utils","text":""},{"location":"api/utils/#utility-functions","title":"Utility functions","text":""},{"location":"api/utils/#flowevidence.utils.EarlyStopping","title":"<code>EarlyStopping</code>","text":"<p>Early stopping class to stop training the flow model when the validation loss does not improve.</p> <p>Parameters:</p> Name Type Description Default <code>patience</code> <code>int</code> <p>Number of epochs to wait before stopping training. Default is 50.</p> <code>50</code> <code>delta</code> <code>float</code> <p>Minimum change in the monitored quantity to qualify as an improvement. Default is 1e-6.</p> <code>0.0001</code> <p>Methods:</p> Name Description <code>__call__</code> <p>Checks if the validation loss has improved.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>class EarlyStopping:\n    \"\"\"\n    Early stopping class to stop training the flow model when the validation loss does not improve.\n\n    Args:\n        patience (int): Number of epochs to wait before stopping training. Default is 50.\n        delta (float): Minimum change in the monitored quantity to qualify as an improvement. Default is 1e-6.\n\n    Methods:\n        __call__(val_loss):\n            Checks if the validation loss has improved.\n    \"\"\"\n\n    def __init__(self, patience: int = 50, delta: float = 1e-4):\n        self.patience = patience\n        self.delta = delta\n        self.counter = 0\n        self.best_loss = float('inf')\n        self.early_stop = False\n\n    def __call__(self, val_loss: float):\n        \"\"\"\n        Checks if the validation loss has improved.\n\n        Args:\n            val_loss (float): The validation loss to check.\n\n        Returns:\n            stop (bool): True if the validation loss has not improved for the specified number of epochs, False otherwise.\n        \"\"\"\n\n        if np.abs(val_loss - self.best_loss) &lt; self.delta:\n            self.counter += 1\n            if self.counter &gt;= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.counter = 0\n\n        return self.early_stop\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.EarlyStopping.__call__","title":"<code>__call__(val_loss)</code>","text":"<p>Checks if the validation loss has improved.</p> <p>Parameters:</p> Name Type Description Default <code>val_loss</code> <code>float</code> <p>The validation loss to check.</p> required <p>Returns:</p> Name Type Description <code>stop</code> <code>bool</code> <p>True if the validation loss has not improved for the specified number of epochs, False otherwise.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def __call__(self, val_loss: float):\n    \"\"\"\n    Checks if the validation loss has improved.\n\n    Args:\n        val_loss (float): The validation loss to check.\n\n    Returns:\n        stop (bool): True if the validation loss has not improved for the specified number of epochs, False otherwise.\n    \"\"\"\n\n    if np.abs(val_loss - self.best_loss) &lt; self.delta:\n        self.counter += 1\n        if self.counter &gt;= self.patience:\n            self.early_stop = True\n    else:\n        self.best_loss = val_loss\n        self.counter = 0\n\n    return self.early_stop\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.cornerplot_training","title":"<code>cornerplot_training(samples, target_distribution=None, epoch=0, plot_dir='./', savename='corner')</code>","text":"<p>Generates a corner plot for the given samples and optionally overlays it with a target distribution.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>ndarray</code> <p>The samples to be plotted.</p> required <code>target_distribution</code> <code>ndarray</code> <p>The target distribution to overlay on the plot. Defaults to None.</p> <code>None</code> <code>epoch</code> <code>int</code> <p>The current epoch number, used for labeling. Defaults to 0.</p> <code>0</code> <code>plot_dir</code> <code>str</code> <p>The directory where the plot will be saved. Defaults to './'.</p> <code>'./'</code> <code>savename</code> <code>str</code> <p>The name of the saved plot file. Defaults to 'corner'.</p> <code>'corner'</code> Source code in <code>flowevidence/utils.py</code> <pre><code>def cornerplot_training(samples: np.ndarray,    \n                        target_distribution: np.ndarray = None,\n                        epoch: int = 0,\n                        plot_dir: str = './',\n                        savename: str = 'corner'\n                        ):\n    \"\"\"\n    Generates a corner plot for the given samples and optionally overlays it with a target distribution.\n\n    Args:\n        samples (np.ndarray): The samples to be plotted.\n        target_distribution (np.ndarray, optional): The target distribution to overlay on the plot. Defaults to None.\n        epoch (int, optional): The current epoch number, used for labeling. Defaults to 0.\n        plot_dir (str, optional): The directory where the plot will be saved. Defaults to './'.\n        savename (str, optional): The name of the saved plot file. Defaults to 'corner'.\n    \"\"\"\n    color_target = 'k'\n    color_samples = \"#5790fc\"\n    if target_distribution is not None:\n        fig = corner(target_distribution, bins=50, color=color_target, weights=np.ones(target_distribution.shape[0])/target_distribution.shape[0])\n        fig = corner(samples, bins=50, color=color_samples, weights=np.ones(samples.shape[0])/samples.shape[0], fig=fig)\n\n        handles = [\n        plt.Line2D([], [], color=color_target, label='Target \\n Distribution'),\n        plt.Line2D([], [], color=color_samples, label='Training @ \\n epoch ' + str(epoch))\n    ]\n    else:\n        fig = corner(samples, bins=50, color=color_samples)\n        handles = [\n        plt.Line2D([], [], color=color_samples, label='Flow @ \\n epoch ' + str(epoch))\n    ]\n\n    ndims = samples.shape[1] # Number of dimensions in the samples\n    axes = np.array(fig.axes).reshape(ndims, ndims)  # Get the axes of the figure\n    axes[0, 1].legend(handles=handles, loc=\"upper left\")  # Add legend to the last axis\n    #plt.tight_layout()\n    plt.savefig(plot_dir + savename)\n    plt.close(fig)\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.create_data_loaders","title":"<code>create_data_loaders(train_samples, val_samples, batch_size=256, num_workers=0, pin_memory=True)</code>","text":"<p>Creates data loaders for training and validation datasets.</p> <p>Parameters:</p> Name Type Description Default <code>train_samples</code> <code>Tensor</code> <p>The training samples.</p> required <code>val_samples</code> <code>Tensor</code> <p>The validation samples.</p> required <code>batch_size</code> <code>int</code> <p>Number of samples per batch to load. Default is 256.</p> <code>256</code> <code>num_workers</code> <code>int</code> <p>How many subprocesses to use for data loading. Default is 0.</p> <code>0</code> <code>pin_memory</code> <code>bool</code> <p>If True, the data loader will copy Tensors into CUDA pinned memory. Default is True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>train_loader</code> <code>DataLoader</code> <p>The training data loader.</p> <code>val_loader</code> <code>DataLoader</code> <p>The validation data loader.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def create_data_loaders(train_samples: torch.tensor, \n                        val_samples: torch.tensor,\n                        batch_size: int = 256, \n                        num_workers: int = 0,\n                        pin_memory: bool = True\n                        ) -&gt; tuple[DataLoader, DataLoader]:\n    \"\"\"\n    Creates data loaders for training and validation datasets.\n\n    Args:\n        train_samples (Tensor): The training samples.\n        val_samples (Tensor): The validation samples.\n        batch_size (int, optional): Number of samples per batch to load. Default is 256.\n        num_workers (int, optional): How many subprocesses to use for data loading. Default is 0.\n        pin_memory (bool, optional): If True, the data loader will copy Tensors into CUDA pinned memory. Default is True.\n\n    Returns:\n        train_loader (DataLoader): The training data loader.\n        val_loader (DataLoader): The validation data loader.\n    \"\"\"\n\n    train_dataset = TensorDataset(train_samples)\n    val_dataset = TensorDataset(val_samples)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n\n    return train_loader, val_loader\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.denormalize_gaussian","title":"<code>denormalize_gaussian(samples, mean, std)</code>","text":"<p>Denormalizes the given samples by adding the mean and scaling by the standard deviation.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>A tensor containing the samples to be destandardized.</p> required <code>mean</code> <code>Tensor</code> <p>The mean of the original samples.</p> required <code>std</code> <code>Tensor</code> <p>The standard deviation of the original samples.</p> required <p>Returns:</p> Name Type Description <code>destandardized_samples</code> <code>Tensor</code> <p>The destandardized samples.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def denormalize_gaussian(samples: torch.tensor, \n                mean: torch.tensor,\n                std: torch.tensor\n                ) -&gt; torch.tensor:\n    \"\"\"\n    Denormalizes the given samples by adding the mean and scaling by the standard deviation.\n\n    Args:\n        samples (torch.Tensor): A tensor containing the samples to be destandardized.\n        mean (torch.Tensor): The mean of the original samples.\n        std (torch.Tensor): The standard deviation of the original samples.\n\n    Returns:\n        destandardized_samples (torch.Tensor): The destandardized samples.\n    \"\"\"\n\n    return samples * std + mean\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.denormalize_minmax","title":"<code>denormalize_minmax(samples, minimum, range)</code>","text":"<p>Denormalizes the given samples by scaling by the range and adding the minimum.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>A tensor containing the samples to be denormalized.</p> required <code>minimum</code> <code>Tensor</code> <p>The minimum value of the original samples.</p> required <code>range</code> <code>Tensor</code> <p>The range of the original samples.</p> required <p>Returns:</p> Name Type Description <code>denormalized_samples</code> <code>Tensor</code> <p>The denormalized samples.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def denormalize_minmax(samples: torch.tensor, \n                minimum: torch.tensor,\n                range: torch.tensor\n                ) -&gt; torch.tensor:\n    \"\"\"\n    Denormalizes the given samples by scaling by the range and adding the minimum.\n\n    Args:\n        samples (torch.Tensor): A tensor containing the samples to be denormalized.\n        minimum (torch.Tensor): The minimum value of the original samples.\n        range (torch.Tensor): The range of the original samples.\n\n    Returns:\n        denormalized_samples (torch.Tensor): The denormalized samples.\n    \"\"\"\n    return samples * range + minimum\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.denormalize_sigmoid","title":"<code>denormalize_sigmoid(samples, *args, **kwargs)</code>","text":"<p>Denormalizes the given samples using the inverse sigmoid function.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>A tensor containing the samples to be denormalized.</p> required <p>Returns:</p> Name Type Description <code>denormalized_samples</code> <code>Tensor</code> <p>The denormalized samples.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def denormalize_sigmoid(samples: torch.tensor,\n                        *args,\n                        **kwargs\n                        ) -&gt; torch.tensor:\n    \"\"\"\n    Denormalizes the given samples using the inverse sigmoid function.\n\n    Args:\n        samples (torch.Tensor): A tensor containing the samples to be denormalized.\n\n    Returns:\n        denormalized_samples (torch.Tensor): The denormalized samples.\n    \"\"\"\n\n    # Avoid division by zero\n    eps = 1e-6\n    x = torch.clamp(samples, eps, 1.0 - eps)\n\n    return -torch.log(1.0 / x - 1.0)\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.l2_regularization","title":"<code>l2_regularization(model, lambdaL2)</code>","text":"<p>Add L2 regularization to the model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model to which L2 regularization will be added.</p> required <code>lambdaL2</code> <code>float</code> <p>The regularization strength.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The L2 regularization</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def l2_regularization(model: nn.Module, \n                      lambdaL2: float\n                      ) -&gt; torch.Tensor:\n    \"\"\"\n    Add L2 regularization to the model.\n\n    Args:\n        model (nn.Module): The model to which L2 regularization will be added.\n        lambdaL2 (float): The regularization strength.\n\n    Returns:\n        torch.Tensor: The L2 regularization\n    \"\"\"\n    l2_reg = torch.tensor(0., requires_grad=True)\n    for param in model.parameters():\n        l2_reg = l2_reg + torch.norm(param, 2)\n    return lambdaL2 * l2_reg\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.loss_fn","title":"<code>loss_fn(model, x)</code>","text":"<p>Computes the negative log likelihood of the given samples under the model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model to evaluate.</p> required <code>x</code> <code>Tensor</code> <p>The samples to evaluate.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The negative log likelihood of the samples under the model.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def loss_fn(model: nn.Module, \n            x: torch.Tensor\n            ) -&gt; torch.Tensor:\n    \"\"\"\n    Computes the negative log likelihood of the given samples under the model.\n\n    Args:\n        model (nn.Module): The model to evaluate.\n        x (torch.Tensor): The samples to evaluate.\n\n    Returns:\n        torch.Tensor: The negative log likelihood of the samples under the model.\n    \"\"\"\n\n    return -model.log_prob(x).mean()\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.lossplot","title":"<code>lossplot(epochs, train_losses, val_losses, plot_dir='./', savename='losses')</code>","text":"<p>Plots the training and validation losses over epochs and saves the plot as an image file.</p> <p>Parameters:</p> Name Type Description Default <code>epochs</code> <code>list or array - like</code> <p>List or array of epoch numbers.</p> required <code>train_losses</code> <code>list or array - like</code> <p>List or array of training losses for each epoch.</p> required <code>val_losses</code> <code>list or array - like</code> <p>List or array of validation losses for each epoch.</p> required <code>plot_dir</code> <code>str</code> <p>Directory where the plot image will be saved. Default is './'.</p> <code>'./'</code> <code>savename</code> <code>str</code> <p>Name of the saved plot image file. Default is 'losses'.</p> <code>'losses'</code> Source code in <code>flowevidence/utils.py</code> <pre><code>def lossplot(epochs: np.ndarray | list, \n             train_losses: np.ndarray | list,\n             val_losses: np.ndarray | list,\n             plot_dir: str = './',\n             savename: str = 'losses'\n             ):\n    \"\"\"\n    Plots the training and validation losses over epochs and saves the plot as an image file.\n\n    Args:\n        epochs (list or array-like): List or array of epoch numbers.\n        train_losses (list or array-like): List or array of training losses for each epoch.\n        val_losses (list or array-like): List or array of validation losses for each epoch.\n        plot_dir (str, optional): Directory where the plot image will be saved. Default is './'.\n        savename (str, optional): Name of the saved plot image file. Default is 'losses'.\n    \"\"\"\n    #ensure they are arrays\n    epochs = np.array(epochs)\n    train_losses = np.array(train_losses)\n    val_losses = np.array(val_losses)\n\n    fig = plt.figure(figsize=(12, 8))\n\n    # set an offset to make all the values positive and allow the semilogy plot\n    # offset = np.abs(min(np.min(train_losses), np.min(val_losses))) + 1\n    # train_losses += offset\n    # val_losses += offset\n\n    plt.plot(epochs, train_losses, '-x', label='Training')\n    plt.plot(epochs, val_losses, '-x', label='Validation')\n\n    plt.legend()\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.tight_layout()\n    plt.savefig(plot_dir + savename)\n    plt.close(fig)\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.normalize_gaussian","title":"<code>normalize_gaussian(samples)</code>","text":"<p>Standardizes the given samples by removing the mean and scaling to unit variance. Add masking operations to deal with NaN values, for example introduced by RJMCMC.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>A tensor containing the samples to be standardized.</p> required <p>Returns:</p> Name Type Description <code>normalized_samples</code> <code>Tensor</code> <p>The standardized samples.</p> <code>mean</code> <code>Tensor</code> <p>The mean of the original samples.</p> <code>std</code> <code>Tensor</code> <p>The standard deviation of the original samples.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def normalize_gaussian(samples: torch.tensor) -&gt; tuple[torch.tensor: torch.tensor, torch.tensor]:\n    \"\"\"\n    Standardizes the given samples by removing the mean and scaling to unit variance. Add masking operations to deal with NaN values, for example introduced by RJMCMC.\n\n    Args:\n        samples (torch.Tensor): A tensor containing the samples to be standardized.\n\n    Returns:\n        normalized_samples (torch.Tensor): The standardized samples.\n        mean (torch.Tensor): The mean of the original samples.\n        std (torch.Tensor): The standard deviation of the original samples.\n    \"\"\"\n    finite_mask = torch.isfinite(samples)  # Boolean mask for finite values\n\n    # Replace non-finite values with 0 (or any placeholder value that won't affect sums)\n    finite_samples = samples.clone()\n    finite_samples[~finite_mask] = 0.0\n\n    # Count of finite values per column\n    count_finite = finite_mask.sum(dim=0)\n\n    # Compute sum of finite values per column\n    sum_finite = finite_samples.sum(dim=0)\n\n    # Column-wise mean: Avoid division by zero\n    mean = sum_finite / count_finite\n    mean[count_finite == 0] = float('nan')  # Set mean to NaN where no finite values exist\n\n    # Compute variance and standard deviation\n    squared_diff = (samples - mean.unsqueeze(0)) ** 2\n    squared_diff[~finite_mask] = 0.0  # Ignore non-finite values\n    variance = squared_diff.sum(dim=0) / count_finite\n    variance[count_finite == 0] = float('nan')  # Set variance to NaN where no finite values exist\n    std = variance.sqrt()  # Standard deviation\n\n    normalized_samples = (samples - mean) / std\n\n    return normalized_samples, mean, std\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.normalize_minmax","title":"<code>normalize_minmax(samples)</code>","text":"<p>Normalizes the given samples by scaling to the range [0, 1].</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>A tensor containing the samples to be normalized.</p> required <p>Returns:</p> Name Type Description <code>normalized_samples</code> <code>Tensor</code> <p>The normalized samples.</p> <code>minimum</code> <code>Tensor</code> <p>The minimum value of the original samples.</p> <code>range</code> <code>Tensor</code> <p>The range of the original samples.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def normalize_minmax(samples: torch.tensor) -&gt; tuple[torch.tensor: torch.tensor, torch.tensor]:\n    \"\"\"\n    Normalizes the given samples by scaling to the range [0, 1].\n\n    Args:\n        samples (torch.Tensor): A tensor containing the samples to be normalized.\n\n    Returns:\n        normalized_samples (torch.Tensor): The normalized samples.\n        minimum (torch.Tensor): The minimum value of the original samples.\n        range (torch.Tensor): The range of the original samples.\n    \"\"\"\n    finite_mask = torch.isfinite(samples)  # Boolean mask for finite values\n\n    # Replace non-finite values with 0 to avoid affecting min and max calculations\n    finite_samples = samples.clone()\n    finite_samples[~finite_mask] = 0.0\n\n    # Compute per-column min and max while ignoring non-finite values\n    min_values = torch.where(finite_mask, samples, float('inf')).min(dim=0).values\n    max_values = torch.where(finite_mask, samples, float('-inf')).max(dim=0).values\n\n    # Compute range, ensuring no division by zero\n    range_values = max_values - min_values\n    range_values[range_values == 0] = float('nan')  # Handle zero range gracefully\n\n    # Normalize samples\n    normalized_samples = (samples - min_values) / range_values\n\n    # Return normalized samples, along with the min and range used for normalization\n    return normalized_samples, min_values, range_values\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.normalize_sigmoid","title":"<code>normalize_sigmoid(samples)</code>","text":"<p>Normalizes the given samples using the sigmoid function.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>A tensor containing the samples to be normalized.</p> required <p>Returns:</p> Name Type Description <code>normalized_samples</code> <code>Tensor</code> <p>The normalized samples.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def normalize_sigmoid(samples: torch.tensor) -&gt; tuple[torch.tensor: torch.tensor, torch.tensor]:\n    \"\"\"\n    Normalizes the given samples using the sigmoid function.\n\n    Args:\n        samples (torch.Tensor): A tensor containing the samples to be normalized.\n\n    Returns:\n        normalized_samples (torch.Tensor): The normalized samples.\n\n    \"\"\"\n\n    normalized_samples = 1.0 / (1.0 + torch.exp(-samples))\n\n    return normalized_samples, None, None\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.setup_logging","title":"<code>setup_logging(verbose=False)</code>","text":"<p>Configures the logging settings for the application.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>If True, sets the logging level to INFO. Otherwise, sets it to WARNING.</p> <code>False</code> Source code in <code>flowevidence/utils.py</code> <pre><code>def setup_logging(verbose=False):\n        \"\"\"\n        Configures the logging settings for the application.\n\n        Args:\n            verbose (bool): If True, sets the logging level to INFO. Otherwise, sets it to WARNING.\n        \"\"\"\n\n        logging.basicConfig(\n            level=logging.INFO if verbose else logging.WARNING,\n            format=\"%(asctime)s - %(levelname)s - %(message)s\"\n        )\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.shuffle","title":"<code>shuffle(samples)</code>","text":"<p>Shuffles the given tensor of samples along the first dimension.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>A tensor containing the samples to be shuffled.</p> required <p>Returns:</p> Type Description <code>tensor</code> <p>torch.Tensor: A tensor with the samples shuffled along the first dimension.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def shuffle(samples: torch.tensor) -&gt; torch.tensor:\n    \"\"\"\n    Shuffles the given tensor of samples along the first dimension.\n\n    Args:\n        samples (torch.Tensor): A tensor containing the samples to be shuffled.\n\n    Returns:\n        torch.Tensor: A tensor with the samples shuffled along the first dimension.\n    \"\"\"\n\n    indices = torch.randperm(samples.size(0))\n    return samples[indices]\n</code></pre>"},{"location":"api/utils/#flowevidence.utils.split","title":"<code>split(samples, train_ratio=0.8)</code>","text":"<p>Splits the given samples into training and validation sets based on the specified training ratio.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>The input samples to be split.</p> required <code>train_ratio</code> <code>float</code> <p>The ratio of samples to be used for training. Defaults to 0.8.</p> <code>0.8</code> <p>Returns:</p> Name Type Description <code>train_samples</code> <code>Tensor</code> <p>The training samples.</p> <code>val_samples</code> <code>Tensor</code> <p>The validation samples.</p> Source code in <code>flowevidence/utils.py</code> <pre><code>def split(samples: torch.tensor, \n          train_ratio: float = 0.8\n          ) -&gt; tuple[torch.tensor, torch.tensor]:\n    \"\"\"\n    Splits the given samples into training and validation sets based on the specified training ratio.\n\n    Args:\n        samples (Tensor): The input samples to be split.\n        train_ratio (float, optional): The ratio of samples to be used for training. Defaults to 0.8.\n\n    Returns:\n        train_samples (Tensor): The training samples.\n        val_samples (Tensor): The validation samples.\n    \"\"\"\n\n    num_train = int(train_ratio * samples.size(0))\n    train_samples = samples[:num_train]\n    val_samples = samples[num_train:]\n    return train_samples, val_samples\n</code></pre>"}]}